{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Machine Learning Skin Cancer Classification using CNN**\n\n","metadata":{}},{"cell_type":"markdown","source":"\nThis project outlines a process for converting a pre-trained machine learning model from PyTorch to the TFLite format, which is optimized for deployment on mobile and edge devices. The specific use case is a skin cancer classification model.\n\nTechnology Used\nPyTorch: A deep learning framework used for the initial model development and training. The model is assumed to be a JIT-compiled PyTorch model (Just-In-Time compilation).\n\nONNX (Open Neural Network Exchange): An open standard for representing machine learning models. It acts as an intermediate format to enable interoperability between different frameworks like PyTorch and TensorFlow.\n\nONNX Runtime: A high-performance inference engine for ONNX models. It's used here to run the ONNX model and get its output, which is a necessary step before wrapping it in a Keras model.\n\nTensorFlow & Keras: The TensorFlow framework is used to wrap the ONNX model into a Keras model using tf.py_function. This allows the ONNX model to be treated as a custom operation within a TensorFlow graph.\n\nTFLite (TensorFlow Lite): A format for running TensorFlow models on mobile, microcontrollers, and other edge devices. It's the final target format for the model in this project.\n\nNumpy: Used for numerical operations, particularly for handling data conversion between PyTorch tensors and numpy arrays, which are required by ONNX Runtime.\n\nAlgorithm Used\nThe core of this project isn't a specific machine learning algorithm but a model conversion pipeline. The algorithm can be summarized in three main steps:\n\nPyTorch JIT to ONNX: The JIT-compiled PyTorch model is converted to the ONNX format. This is done using torch.onnx.export, which takes a dummy input tensor to trace the model's computation graph and save it as an ONNX file.\n\nONNX to Keras Wrapper: The ONNX model is not directly converted to a Keras model. Instead, a custom Keras Model wrapper class, ONNXModelWrapper, is created. This wrapper uses tf.py_function to call the ONNX Runtime for inference, effectively treating the entire ONNX model as a single custom operation within a TensorFlow graph.\n\nKeras SavedModel to TFLite: The wrapped Keras model is saved as a TensorFlow SavedModel. Then, the tf.lite.TFLiteConverter is used to convert this SavedModel into a TFLite file. Crucially, converter.allow_custom_ops = True is set to ensure that the tf.py_function (which runs the ONNX inference) is preserved as a custom operation in the final TFLite model, preventing conversion errors.\n\nWhy This Project Is Important\nThis project provides a robust solution for a common problem: deploying models trained in one framework (PyTorch) to an ecosystem that primarily supports another (TFLite for mobile/edge).\n\nFramework Interoperability: It demonstrates how to bridge the gap between PyTorch, a popular framework for research and training, and TensorFlow Lite, which is the de-facto standard for on-device inference.\n\nLeveraging Existing Models: It allows developers to use high-quality, pre-trained PyTorch models without having to retrain them in TensorFlow, saving significant time and computational resources.\n\nOptimized Deployment: TFLite models are highly optimized for size and performance on resource-constrained devices. This pipeline makes it possible to take advantage of these optimizations for models originally developed in PyTorch.\n\nHandling Complex Operations: The use of tf.py_function and allow_custom_ops is a key takeaway, as it provides a general method for handling model operations that are not natively supported by the TFLite converter.\n\nUseful Information for Developers and Scientists\nInput Shape is Critical: The dummy_input tensor's shape in the torch.onnx.export call must exactly match the expected input shape of your PyTorch model. Mismatches will cause the export to fail. Similarly, the input_signature in the Keras wrapper's call method must reflect the correct input shape.\n\ntf.py_function Overhead: While tf.py_function is a powerful tool, it does introduce some overhead because it involves a context switch between the TensorFlow graph and native Python code. For performance-critical applications, it's a good idea to profile the TFLite model to ensure this overhead is acceptable.\n\nONNX Runtime Providers: The line sess = ort.InferenceSession(..., providers=['CPUExecutionProvider']) specifies the backend for ONNX inference. Other providers like CUDAExecutionProvider are available for GPU acceleration, but CPUExecutionProvider is a safe and widely supported default.\n\nOutput Shape for tf.py_function: The Tout and name parameters in tf.py_function are crucial for the converter to build the graph correctly. For the TFLite conversion to succeed, you might need to manually set the output shape using output_shapes=[tf.TensorShape([None, output_dim])] or a similar method, depending on your model's output. The current implementation uses a placeholder, which might need to be refined for production use.\n\nModel Pathing: The code uses placeholder paths like /kaggle/input/models/.... Developers and scientists need to update these paths to their specific environment. The use of /kaggle/ suggests this code was developed in a Kaggle notebook, which is a common practice for data science projects.\n\nDependency Management: This project has several dependencies (torch, onnx, onnxruntime, tensorflow, numpy). All of these must be correctly installed and compatible with each other to run the pipeline successfully.\n\nCustom Operations in TFLite: The resulting TFLite model will contain a custom operation for the ONNX inference. To run this model on a device, the TFLite interpreter must be able to handle custom operations. This often requires writing a C++ custom operator kernel to implement the Python tf.py_function logic, or using a TFLite interpreter that supports a Python backend.\n\nModel Quantization: The presented pipeline doesn't include any quantization steps. For further optimization on edge devices, developers can integrate TFLite's post-training quantization, which reduces model size and latency, into this workflow after the TFLite conversion.\n\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Disclaimer**\n\n* Production Readiness and Model Quality: The primary objective of this project is to demonstrate a viable technical pipeline for model conversion, specifically from a JIT-compiled PyTorch model to a TFLite format for integration with Android using AI Edge Gallery and other platforms like Ollama/Gemma3N on an offline laptop. This model is not production-ready. It has not been subjected to rigorous performance, accuracy, or bias testing. The code serves as a proof-of-concept for the conversion process, and any further development would require extensive model improvement and validation before real-world deployment.\n\n* Not a Medical Tool; No Medical Advice: The output from this model, whether used in an Android app or integrated with an LLM like Gemma3N, is not a substitute for professional medical advice, diagnosis, or treatment. This model is an experimental tool for pattern recognition and should never be used as a replacement for consulting a qualified healthcare professional.\n\n* Framework-Specifics: This project outlines a successful conversion path, but the process may not be universally applicable to all PyTorch models. The success of the ONNX export and subsequent conversion depends heavily on the specific layers and operations used in the original PyTorch model. Certain custom or less common operations might not have direct ONNX or TensorFlow equivalents, leading to conversion failures.\n\n* Performance and Overhead: The use of tf.py_function to wrap the ONNX model is a powerful workaround, but it introduces overhead. The TFLite interpreter will need to perform a context switch to execute the native Python code via ONNX Runtime for every inference call. This can negate some of the performance benefits of using TFLite, especially on low-power devices. The final TFLite model is not a fully \"native\" TensorFlow Lite model.\n\n* TFLite Custom Operator Support: The resulting TFLite model relies on a custom operator to run the ONNX inference. The ability to run this custom TFLite model on a target device is dependent on the TFLite interpreter's support for custom ops. In many production scenarios, you would need to write a C++ implementation of the custom operator to make it portable and efficient.\n\n* Assumptions and Placeholders: The code contains assumptions, such as the file path /kaggle/input/... and a placeholder for the output shape within tf.py_function. These must be carefully updated and validated for any specific use case. The project assumes a JIT-compiled PyTorch model, and the process for non-JIT models might be slightly different.\n\n* Lack of Quantization: The pipeline does not include any model quantization, which is a critical step for deploying models on resource-constrained devices to reduce size and improve latency.\n\n* This is utilized for working on an output for skin cancer with the existing dataset in Kaggle. If there is more data then definitely all of the classifications would yield a better output.  Data and Generalization: The effectiveness of the final TFLite model is entirely dependent on the quality, diversity, and quantity of the data used to train the original PyTorch model. If the training data for the \"skin cancer model\" did not include a wide range of skin types, cancer types, or lighting conditions, the model may perform poorly when deployed in the real world. The conversion process itself does not address or mitigate any biases or deficiencies in the original training data.\n\n","metadata":{}},{"cell_type":"markdown","source":"# **Model Training Data**\n\nhttps://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Training Code**","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T14:02:05.505047Z","iopub.execute_input":"2025-08-01T14:02:05.505345Z","iopub.status.idle":"2025-08-01T14:02:18.887784Z","shell.execute_reply.started":"2025-08-01T14:02:05.505316Z","shell.execute_reply":"2025-08-01T14:02:18.886992Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n# 1. Load metadata\nmetadata_path = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\nimage_dir1 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1'\nimage_dir2 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2'\n\ndf = pd.read_csv(metadata_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:33:31.111963Z","iopub.execute_input":"2025-08-01T01:33:31.112372Z","iopub.status.idle":"2025-08-01T01:33:31.179406Z","shell.execute_reply.started":"2025-08-01T01:33:31.112345Z","shell.execute_reply":"2025-08-01T01:33:31.177995Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Map lesion types\nlesion_type_dict = {\n    'nv': 0,\n    'mel': 1,\n    'bkl': 2,\n    'bcc': 3,\n    'akiec': 4,\n    'vasc': 5,\n    'df': 6\n}\n\ndf['label'] = df['dx'].map(lesion_type_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:33:34.319099Z","iopub.execute_input":"2025-08-01T01:33:34.319392Z","iopub.status.idle":"2025-08-01T01:33:34.339511Z","shell.execute_reply.started":"2025-08-01T01:33:34.319372Z","shell.execute_reply":"2025-08-01T01:33:34.338522Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n# Build full image paths\ndef get_image_path(image_id):\n    # Images split between two folders\n    path1 = os.path.join(image_dir1, image_id + '.jpg')\n    if os.path.exists(path1):\n        return path1\n    path2 = os.path.join(image_dir2, image_id + '.jpg')\n    if os.path.exists(path2):\n        return path2\n    return None\n\ndf['image_path'] = df['image_id'].apply(get_image_path)\ndf = df.dropna(subset=['image_path'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:33:36.652375Z","iopub.execute_input":"2025-08-01T01:33:36.652737Z","iopub.status.idle":"2025-08-01T01:34:08.402265Z","shell.execute_reply.started":"2025-08-01T01:33:36.652711Z","shell.execute_reply":"2025-08-01T01:34:08.401172Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# 2. Define dataset\nclass SkinCancerDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.loc[idx, 'image_path']\n        label = self.df.loc[idx, 'label']\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:09.951925Z","iopub.execute_input":"2025-08-01T01:34:09.952300Z","iopub.status.idle":"2025-08-01T01:34:09.963197Z","shell.execute_reply.started":"2025-08-01T01:34:09.952269Z","shell.execute_reply":"2025-08-01T01:34:09.961251Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\n# 3. Transforms: resize all images to 75x100 (height x width) and normalize\nimage_size = (75, 100)\nmean = [0.485, 0.456, 0.406]  # ImageNet means (common practice)\nstd = [0.229, 0.224, 0.225]   # ImageNet stds\n\ntrain_transform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.RandomRotation(10),\n    transforms.RandomResizedCrop(image_size, scale=(0.9, 1.1)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n\nval_test_transform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:14.619098Z","iopub.execute_input":"2025-08-01T01:34:14.619540Z","iopub.status.idle":"2025-08-01T01:34:14.628399Z","shell.execute_reply.started":"2025-08-01T01:34:14.619509Z","shell.execute_reply":"2025-08-01T01:34:14.627260Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 4. Split data into train, val, test\ntrain_df, test_df = train_test_split(df, test_size=0.20, random_state=42, stratify=df['label'])\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df['label'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:17.064598Z","iopub.execute_input":"2025-08-01T01:34:17.065381Z","iopub.status.idle":"2025-08-01T01:34:17.091233Z","shell.execute_reply.started":"2025-08-01T01:34:17.065347Z","shell.execute_reply":"2025-08-01T01:34:17.089979Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 5. Create datasets and dataloaders\nbatch_size = 32\n\ntrain_dataset = SkinCancerDataset(train_df, transform=train_transform)\nval_dataset = SkinCancerDataset(val_df, transform=val_test_transform)\ntest_dataset = SkinCancerDataset(test_df, transform=val_test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:19.580204Z","iopub.execute_input":"2025-08-01T01:34:19.580522Z","iopub.status.idle":"2025-08-01T01:34:19.589155Z","shell.execute_reply.started":"2025-08-01T01:34:19.580502Z","shell.execute_reply":"2025-08-01T01:34:19.587687Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# 6. Define CNN model \nclass SkinCNN(nn.Module):\n    def __init__(self, num_classes=7):\n        super(SkinCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),  # input channels = 3 (RGB)\n            nn.ReLU(),\n            nn.Conv2d(32, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout(0.25),\n\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout(0.4)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * (image_size[0] // 4) * (image_size[1] // 4), 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SkinCNN(num_classes=7).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:22.252848Z","iopub.execute_input":"2025-08-01T01:34:22.253186Z","iopub.status.idle":"2025-08-01T01:34:22.319001Z","shell.execute_reply.started":"2025-08-01T01:34:22.253161Z","shell.execute_reply":"2025-08-01T01:34:22.317877Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\n# 7. Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:26.120378Z","iopub.execute_input":"2025-08-01T01:34:26.120740Z","iopub.status.idle":"2025-08-01T01:34:26.126787Z","shell.execute_reply.started":"2025-08-01T01:34:26.120714Z","shell.execute_reply":"2025-08-01T01:34:26.125414Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 8. Training loop\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    return running_loss / total, correct / total\n\ndef eval_model(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item() * images.size(0)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    return running_loss / total, correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:29.749742Z","iopub.execute_input":"2025-08-01T01:34:29.750071Z","iopub.status.idle":"2025-08-01T01:34:29.758277Z","shell.execute_reply.started":"2025-08-01T01:34:29.750046Z","shell.execute_reply":"2025-08-01T01:34:29.757268Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\n# 9. Run training with early stopping and learning rate scheduler\nnum_epochs = 50\nbest_val_acc = 0\npatience = 5\ntrigger_times = 0\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5, verbose=True)\n\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = eval_model(model, val_loader, criterion, device)\n    scheduler.step(val_acc)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n    # Early stopping\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        trigger_times = 0\n        torch.save(model.state_dict(), 'skin_cancer_model.pt')  # save best model\n    else:\n        trigger_times += 1\n        if trigger_times >= patience:\n            print(\"Early stopping triggered.\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T01:34:33.865934Z","iopub.execute_input":"2025-08-01T01:34:33.866261Z","iopub.status.idle":"2025-08-01T03:11:47.903447Z","shell.execute_reply.started":"2025-08-01T01:34:33.866239Z","shell.execute_reply":"2025-08-01T03:11:47.902012Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/50] Train Loss: 1.0166, Train Acc: 0.6662 | Val Loss: 0.8530, Val Acc: 0.6696\nEpoch [2/50] Train Loss: 0.9088, Train Acc: 0.6712 | Val Loss: 0.8566, Val Acc: 0.6696\nEpoch [3/50] Train Loss: 0.8751, Train Acc: 0.6778 | Val Loss: 0.8118, Val Acc: 0.7007\nEpoch [4/50] Train Loss: 0.8616, Train Acc: 0.6847 | Val Loss: 0.8127, Val Acc: 0.6945\nEpoch [5/50] Train Loss: 0.8302, Train Acc: 0.6878 | Val Loss: 0.7931, Val Acc: 0.6970\nEpoch [6/50] Train Loss: 0.8185, Train Acc: 0.6947 | Val Loss: 0.7889, Val Acc: 0.7132\nEpoch [7/50] Train Loss: 0.7934, Train Acc: 0.7039 | Val Loss: 0.7558, Val Acc: 0.7232\nEpoch [8/50] Train Loss: 0.7713, Train Acc: 0.7165 | Val Loss: 0.7206, Val Acc: 0.7307\nEpoch [9/50] Train Loss: 0.7630, Train Acc: 0.7255 | Val Loss: 0.7204, Val Acc: 0.7282\nEpoch [10/50] Train Loss: 0.7448, Train Acc: 0.7282 | Val Loss: 0.7075, Val Acc: 0.7456\nEpoch [11/50] Train Loss: 0.7263, Train Acc: 0.7325 | Val Loss: 0.7014, Val Acc: 0.7332\nEpoch [12/50] Train Loss: 0.7172, Train Acc: 0.7333 | Val Loss: 0.7002, Val Acc: 0.7569\nEpoch [13/50] Train Loss: 0.6980, Train Acc: 0.7424 | Val Loss: 0.6815, Val Acc: 0.7469\nEpoch [14/50] Train Loss: 0.6855, Train Acc: 0.7474 | Val Loss: 0.6693, Val Acc: 0.7618\nEpoch [15/50] Train Loss: 0.6816, Train Acc: 0.7470 | Val Loss: 0.6687, Val Acc: 0.7606\nEpoch [16/50] Train Loss: 0.6762, Train Acc: 0.7526 | Val Loss: 0.6545, Val Acc: 0.7656\nEpoch [17/50] Train Loss: 0.6740, Train Acc: 0.7466 | Val Loss: 0.6620, Val Acc: 0.7618\nEpoch [18/50] Train Loss: 0.6569, Train Acc: 0.7531 | Val Loss: 0.6581, Val Acc: 0.7581\nEpoch [19/50] Train Loss: 0.6599, Train Acc: 0.7542 | Val Loss: 0.6737, Val Acc: 0.7519\nEpoch [20/50] Train Loss: 0.6402, Train Acc: 0.7609 | Val Loss: 0.6647, Val Acc: 0.7643\nEpoch [21/50] Train Loss: 0.6031, Train Acc: 0.7702 | Val Loss: 0.6325, Val Acc: 0.7668\nEpoch [22/50] Train Loss: 0.5981, Train Acc: 0.7705 | Val Loss: 0.6241, Val Acc: 0.7631\nEpoch [23/50] Train Loss: 0.5778, Train Acc: 0.7843 | Val Loss: 0.6320, Val Acc: 0.7594\nEpoch [24/50] Train Loss: 0.5823, Train Acc: 0.7804 | Val Loss: 0.6419, Val Acc: 0.7631\nEpoch [25/50] Train Loss: 0.5725, Train Acc: 0.7807 | Val Loss: 0.6470, Val Acc: 0.7706\nEpoch [26/50] Train Loss: 0.5647, Train Acc: 0.7867 | Val Loss: 0.6317, Val Acc: 0.7731\nEpoch [27/50] Train Loss: 0.5606, Train Acc: 0.7875 | Val Loss: 0.6543, Val Acc: 0.7531\nEpoch [28/50] Train Loss: 0.5612, Train Acc: 0.7839 | Val Loss: 0.6342, Val Acc: 0.7643\nEpoch [29/50] Train Loss: 0.5565, Train Acc: 0.7892 | Val Loss: 0.6339, Val Acc: 0.7756\nEpoch [30/50] Train Loss: 0.5386, Train Acc: 0.7938 | Val Loss: 0.6372, Val Acc: 0.7668\nEpoch [31/50] Train Loss: 0.5508, Train Acc: 0.7888 | Val Loss: 0.6401, Val Acc: 0.7731\nEpoch [32/50] Train Loss: 0.5304, Train Acc: 0.7947 | Val Loss: 0.6405, Val Acc: 0.7718\nEpoch [33/50] Train Loss: 0.5180, Train Acc: 0.8039 | Val Loss: 0.6624, Val Acc: 0.7631\nEpoch [34/50] Train Loss: 0.5099, Train Acc: 0.8064 | Val Loss: 0.6523, Val Acc: 0.7718\nEarly stopping triggered.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# **Model Results**","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"**What the model is learning**\n\nHere's what we can infer:\n\nâœ… Improvement in Accuracy\nTraining Accuracy increases steadily:\n\nFrom 66.6% at epoch 1 â†’ ~78.6% at epoch 27.\n\nValidation Accuracy also improves:\n\nFrom 68.7% â†’ ~77.4%\n\nThis means the model is learning and generalizing reasonably well.\n\nðŸ“‰ Loss Trends\nTraining Loss drops from 0.9777 â†’ 0.5708\n\nValidation Loss drops from 0.9429 â†’ fluctuates around 0.65-0.67\n\nThis suggests a decent reduction in error, though validation loss fluctuates, which is common.","metadata":{}},{"cell_type":"code","source":"# 10. Load best model and evaluate on test set\nmodel.load_state_dict(torch.load('skin_cancer_model.pt'))\ntest_loss, test_acc = eval_model(model, test_loader, criterion, device)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:11:17.492274Z","iopub.execute_input":"2025-07-31T23:11:17.494613Z","iopub.status.idle":"2025-07-31T23:11:39.976326Z","shell.execute_reply.started":"2025-07-31T23:11:17.494557Z","shell.execute_reply":"2025-07-31T23:11:39.974893Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.6610, Test Accuracy: 0.7494\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# 11. Confusion matrix on test set\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        preds = outputs.argmax(dim=1).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.numpy())\n\ncm = confusion_matrix(all_labels, all_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=list(lesion_type_dict.keys()))\ndisp.plot(cmap=plt.cm.Blues)\nplt.title(\"Confusion Matrix on Test Set\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:11:59.278284Z","iopub.execute_input":"2025-07-31T23:11:59.278734Z","iopub.status.idle":"2025-07-31T23:12:18.151639Z","shell.execute_reply.started":"2025-07-31T23:11:59.278699Z","shell.execute_reply":"2025-07-31T23:12:18.150435Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAh8AAAHHCAYAAAAf2DoOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACJS0lEQVR4nOzdd1xT1/vA8U8AGbKHgCiCgyLuUfcAq3Vvq1Wpe7R110WtW1tt3avO1lm12jrqrta96katdU+sAgpiRGRI7u8Pf6SmDBmBQL7P21deL3Puyb3PSULy5Jxzz1UpiqIghBBCCJFDTAwdgBBCCCH+t0jyIYQQQogcJcmHEEIIIXKUJB9CCCGEyFGSfAghhBAiR0nyIYQQQogcJcmHEEIIIXKUJB9CCCGEyFGSfAghhBAiR0nyIfK8mzdv0rBhQ+zt7VGpVGzdulWv+7937x4qlYqVK1fqdb95WUBAAAEBAYYOQwiRR0nyIfTi9u3bfPrppxQrVgxLS0vs7OyoVasWc+fO5dWrV9l67G7dunH58mW++eYb1qxZw/vvv5+tx8tJ3bt3R6VSYWdnl+LzePPmTVQqFSqVihkzZmR4/48ePWLChAkEBwfrIdrcKyAgQPs8pXWbMGGCXo63cOHCDCWr0dHRjB8/njJlymBtbY2zszMVKlRg8ODBPHr0KMPH//vvv5kwYQL37t3L8GOFyAlmhg5A5H07d+6kffv2WFhY0LVrV8qUKUN8fDzHjh1jxIgRXLlyhaVLl2bLsV+9esXJkycZPXo0AwYMyJZjeHl58erVK/Lly5ct+38XMzMzYmJi2L59Ox06dNDZtnbtWiwtLYmNjc3Uvh89esTEiRPx9vamQoUK6X7c3r17M3U8Qxk9ejS9e/fW3j9z5gzz5s3jq6++ws/PT1terlw5vRxv4cKFuLi40L1793fWTUhIoG7duly7do1u3boxcOBAoqOjuXLlCuvWraNNmzZ4eHhk6Ph///03EydOJCAgAG9v78w1QohsJMmHyJK7d+/SsWNHvLy8OHDgAAULFtRu69+/P7du3WLnzp3ZdvwnT54A4ODgkG3HUKlUWFpaZtv+38XCwoJatWqxfv36ZMnHunXraNasGZs2bcqRWGJiYsifPz/m5uY5cjx9+fDDD3XuW1paMm/ePD788EODDx9t3bqVCxcusHbtWjp37qyzLTY2lvj4eANFJkT2kWEXkSXTpk0jOjqaH3/8USfxSFKiRAkGDx6svf/69WsmT55M8eLFsbCwwNvbm6+++oq4uDidx3l7e9O8eXOOHTtG1apVsbS0pFixYqxevVpbZ8KECXh5eQEwYsQIVCqV9lde9+7dU/zFN2HCBFQqlU7Zvn37qF27Ng4ODtjY2ODr68tXX32l3Z7anI8DBw5Qp04drK2tcXBwoFWrVly9ejXF4926dYvu3bvj4OCAvb09PXr0ICYmJvUn9j86d+7M7t27iYqK0padOXOGmzdvJvvCAoiMjGT48OGULVsWGxsb7OzsaNKkCRcvXtTWOXToEFWqVAGgR48e2qGHpHYGBARQpkwZzp07R926dcmfP7/2efnvnI9u3bphaWmZrP2NGjXC0dHxnUMHL1++ZNiwYXh6emJhYYGvry8zZszgvxfdVqlUDBgwgK1bt1KmTBksLCwoXbo0e/bseedzmB67d+/Wvqa2trY0a9aMK1eu6NQJDQ2lR48eFC5cGAsLCwoWLEirVq20Qxze3t5cuXKFw4cPa5/TtBKc27dvA1CrVq1k25KGMN927do1PvroI5ycnLC0tOT9999n27Zt2u0rV66kffv2ANSrV08bw6FDhzLxjAiRPST5EFmyfft2ihUrRs2aNdNVv3fv3owbN45KlSoxe/Zs/P39mTp1Kh07dkxW99atW3z00Ud8+OGHzJw5E0dHR7p37679Mmjbti2zZ88GoFOnTqxZs4Y5c+ZkKP4rV67QvHlz4uLimDRpEjNnzqRly5YcP348zcf98ccfNGrUiPDwcCZMmMDQoUM5ceIEtWrVSnGcvUOHDrx48YKpU6fSoUMHVq5cycSJE9MdZ9u2bVGpVGzevFlbtm7dOkqWLEmlSpWS1b9z5w5bt26lefPmzJo1ixEjRnD58mX8/f21iYCfnx+TJk0CoG/fvqxZs4Y1a9ZQt25d7X4iIiJo0qQJFSpUYM6cOdSrVy/F+ObOnUuBAgXo1q0biYmJACxZsoS9e/cyf/78NIcNFEWhZcuWzJ49m8aNGzNr1ix8fX0ZMWIEQ4cOTVb/2LFj9OvXj44dOzJt2jRiY2Np164dERER6XgmU7dmzRqaNWuGjY0N3333HWPHjuXvv/+mdu3aOq9pu3bt2LJlCz169GDhwoUMGjSIFy9e8ODBAwDmzJlD4cKFKVmypPY5HT16dKrHTUqgV69enSzZ+q8rV65QvXp1rl69ypdffsnMmTOxtramdevWbNmyBYC6desyaNAgAL766ittDG8PLwlhcIoQmfT8+XMFUFq1apWu+sHBwQqg9O7dW6d8+PDhCqAcOHBAW+bl5aUAypEjR7Rl4eHhioWFhTJs2DBt2d27dxVAmT59us4+u3Xrpnh5eSWLYfz48crbb/vZs2crgPLkyZNU4046xooVK7RlFSpUUFxdXZWIiAht2cWLFxUTExOla9euyY7Xs2dPnX22adNGcXZ2TvWYb7fD2tpaURRF+eijj5T69esriqIoiYmJiru7uzJx4sQUn4PY2FglMTExWTssLCyUSZMmacvOnDmTrG1J/P39FUBZvHhxitv8/f11yn7//XcFUL7++mvlzp07io2NjdK6det3tnHr1q3ax73to48+UlQqlXLr1i1tGaCYm5vrlF28eFEBlPnz57/zWEl++eUXBVAOHjyoKIqivHjxQnFwcFD69OmjUy80NFSxt7fXlj979izF99t/lS5dOtnzk5qYmBjF19dXARQvLy+le/fuyo8//qiEhYUlq1u/fn2lbNmySmxsrLZMo9EoNWvWVHx8fFJtnxC5jfR8iExTq9UA2Nrapqv+rl27AJL9mh02bBhAsrkhpUqVok6dOtr7BQoUwNfXlzt37mQ65v9Kmivy22+/odFo0vWYx48fExwcTPfu3XFyctKWlytXjg8//FDbzrd99tlnOvfr1KlDRESE9jlMj86dO3Po0CFCQ0M5cOAAoaGhKQ65wJt5IiYmb/68ExMTiYiI0A4pnT9/Pt3HtLCwoEePHumq27BhQz799FMmTZpE27ZtsbS0ZMmSJe983K5duzA1NdX+Wk8ybNgwFEVh9+7dOuUNGjSgePHi2vvlypXDzs4uS++Lffv2ERUVRadOnXj69Kn2ZmpqSrVq1Th48CAAVlZWmJubc+jQIZ49e5bp473NysqKU6dOMWLECODNsEmvXr0oWLAgAwcO1A5JRkZGcuDAAW0vWlKMERERNGrUiJs3b/LPP//oJSYhspskHyLTksaiX7x4ka769+/fx8TEhBIlSuiUu7u74+DgwP3793XKixQpkmwfjo6OevvQB/j444+pVasWvXv3xs3NjY4dO7Jx48Y0E5GkOH19fZNt8/Pz4+nTp7x8+VKn/L9tcXR0BMhQW5o2bYqtrS0bNmxg7dq1VKlSJdlzmUSj0TB79mx8fHywsLDAxcWFAgUKcOnSJZ4/f57uYxYqVChDk0tnzJiBk5MTwcHBzJs3D1dX13c+5v79+3h4eCRLYpOGCXLifXHz5k0APvjgAwoUKKBz27t3L+Hh4cCbZOy7775j9+7duLm5UbduXaZNm0ZoaGimjw1gb2/PtGnTuHfvHvfu3ePHH3/E19eXBQsWMHnyZODNMKSiKIwdOzZZjOPHjwfQxilEbidnu4hMs7Ozw8PDg7/++itDj/vvhM/UmJqapliuvGNcPK1jJM1HSGJlZcWRI0c4ePAgO3fuZM+ePWzYsIEPPviAvXv3phpDRmWlLUksLCxo27Ytq1at4s6dO2muSTFlyhTGjh1Lz549mTx5Mk5OTpiYmDBkyJB09/DAm+cnIy5cuKD9Arx8+TKdOnXK0OPTQx/P5X8lPSdr1qzB3d092XYzs38/KocMGUKLFi3YunUrv//+O2PHjmXq1KkcOHCAihUrZjqGJF5eXvTs2ZM2bdpQrFgx1q5dy9dff62Ncfjw4TRq1CjFx6aWjAqR20jyIbKkefPmLF26lJMnT1KjRo0063p5eaHRaLh586bO5LewsDCioqK0E+/0wdHRUefMkCT//RUNYGJiQv369alfvz6zZs1iypQpjB49moMHD9KgQYMU2wFw/fr1ZNuuXbuGi4sL1tbWWW9ECjp37szy5csxMTFJcZJukl9//ZV69erx448/6pRHRUXh4uKivZ/eRDA9Xr58SY8ePShVqhQ1a9Zk2rRptGnTRntGTWq8vLz4448/ePHihU7vx7Vr17Tbs1vSMI6rq2uKr3lK9YcNG8awYcO4efMmFSpUYObMmfz000+Afp5XR0dHihcvrk3uixUrBkC+fPneGaM+X1chsoMMu4gsGTlyJNbW1vTu3ZuwsLBk22/fvs3cuXOBN8MGQLIzUmbNmgVAs2bN9BZX8eLFef78OZcuXdKWPX78WHtGQJLIyMhkj01abOu/p/8mKViwIBUqVGDVqlU6Cc5ff/3F3r17te3MDvXq1WPy5MksWLAgxV/oSUxNTZP1BPzyyy/J5gQkJUkpJWoZFRQUxIMHD1i1ahWzZs3C29ubbt26pfo8JmnatCmJiYksWLBAp3z27NmoVCqaNGmS5djepVGjRtjZ2TFlyhQSEhKSbU9aTyYmJibZgm7FixfH1tZWp53W1tbpfk4vXrzI06dPk5Xfv3+fv//+Wzu85+rqSkBAAEuWLOHx48epxph0fNDP6ypEdpCeD5ElxYsXZ926dXz88cf4+fnprHB64sQJfvnlF+0qj+XLl6dbt24sXbqUqKgo/P39OX36NKtWraJ169apnsaZGR07diQoKIg2bdowaNAgYmJiWLRoEe+9957OhMtJkyZx5MgRmjVrhpeXF+Hh4SxcuJDChQtTu3btVPc/ffp0mjRpQo0aNejVqxevXr1i/vz52Nvb622J7pSYmJgwZsyYd9Zr3rw5kyZNokePHtSsWZPLly+zdu1a7a/nJMWLF8fBwYHFixdja2uLtbU11apVo2jRohmK68CBAyxcuJDx48drT/1dsWIFAQEBjB07lmnTpqX62BYtWlCvXj1Gjx7NvXv3KF++PHv37uW3335jyJAhOpNLs4udnR2LFi2iS5cuVKpUiY4dO1KgQAEePHjAzp07qVWrFgsWLODGjRvUr1+fDh06UKpUKczMzNiyZQthYWE6PVGVK1dm0aJFfP3115QoUQJXV1c++OCDFI+9b98+xo8fT8uWLalevTo2NjbcuXOH5cuXExcXp/N++v7776lduzZly5alT58+FCtWjLCwME6ePMnDhw+167hUqFABU1NTvvvuO54/f46FhQUffPBBuubgCJEjDHmqjTAeN27cUPr06aN4e3sr5ubmiq2trVKrVi1l/vz5OqcFJiQkKBMnTlSKFi2q5MuXT/H09FRGjRqlU0dR3pxq26xZs2TH+e8pnqmdaqsoirJ3716lTJkyirm5ueLr66v89NNPyU613b9/v9KqVSvFw8NDMTc3Vzw8PJROnTopN27cSHaM/56O+scffyi1atVSrKysFDs7O6VFixbK33//rVMn6Xj/PZV3xYoVCqDcvXs31edUUXRPtU1NaqfaDhs2TClYsKBiZWWl1KpVSzl58mSKp8j+9ttvSqlSpRQzMzOddvr7+yulS5dO8Zhv70etViteXl5KpUqVlISEBJ16X3zxhWJiYqKcPHkyzTa8ePFC+eKLLxQPDw8lX758io+PjzJ9+nRFo9Ho1AOU/v37J3u8l5eX0q1btzSP8bbUTkU9ePCg0qhRI8Xe3l6xtLRUihcvrnTv3l05e/asoiiK8vTpU6V///5KyZIlFWtra8Xe3l6pVq2asnHjRp39hIaGKs2aNVNsbW0VIM3Tbu/cuaOMGzdOqV69uuLq6qqYmZkpBQoUUJo1a6Zz+nmS27dvK127dlXc3d2VfPnyKYUKFVKaN2+u/Prrrzr1li1bphQrVkwxNTWV025FrqNSlCzM0hJCCCGEyCCZ8yGEEEKIHCXJhxBCCCFylCQfQgghhMhRknwIIYQQIkdJ8iGEEEKIHCXJhxBCCCFylCwylgEajYZHjx5ha2sryxcLIUQepCgKL168wMPDQ3vlZ32LjY0lPj5eL/syNzfH0tJSL/vKTST5yIBHjx7h6elp6DCEEEJkUUhICIULF9b7fmNjY7GydYbXMXrZn7u7O3fv3jW6BESSjwxIuuiVealuqEzTf5nx3O7G3u8MHYL+GVnHlLmp8Y2QmpgY2Ysk8oQXajUlinrqXMRQn+Lj4+F1DBalukFWvycS4wn9exXx8fGSfPwvSxpqUZmaG1XyYWdnZ+gQ9M/Ivtck+RBCv7J96NzMMsvfE4rK+P7uk0jyIYQQQuibCshqgmPE+bnxplVCCCGEoahM9HPLgCNHjtCiRQs8PDxQqVRs3bpVuy0hIYGgoCDKli2LtbU1Hh4edO3alUePHunsIzIyksDAQOzs7HBwcKBXr15ER0fr1Ll06RJ16tTB0tIST0/PNK9anRpJPoQQQggj8PLlS8qXL8/333+fbFtMTAznz59n7NixnD9/ns2bN3P9+nVatmypUy8wMJArV66wb98+duzYwZEjR+jbt692u1qtpmHDhnh5eXHu3DmmT5/OhAkTWLp0aYZilWEXIYQQQt9UKj0Mu2Ts8U2aNKFJkyYpbrO3t2ffvn06ZQsWLKBq1ao8ePCAIkWKcPXqVfbs2cOZM2d4//33AZg/fz5NmzZlxowZeHh4sHbtWuLj41m+fDnm5uaULl2a4OBgZs2apZOkvIv0fAghhBD6psdhF7VarXOLi4vTS4jPnz9HpVLh4OAAwMmTJ3FwcNAmHgANGjTAxMSEU6dOaevUrVsXc/N/J9M2atSI69ev8+zZs3QfW5IPIYQQIhfz9PTE3t5ee5s6dWqW9xkbG0tQUBCdOnXSnvEYGhqKq6urTj0zMzOcnJwIDQ3V1nFzc9Opk3Q/qU56yLCLEEIIoW96HHYJCQnRWRLBwsIiS7tNSEigQ4cOKIrCokWLsrSvzJLkQwghhNC7jJ+tkuI+eLMWk77WY0pKPO7fv8+BAwd09uvu7k54eLhO/devXxMZGYm7u7u2TlhYmE6dpPtJddJDhl2EEEKI/wFJicfNmzf5448/cHZ21tleo0YNoqKiOHfunLbswIEDaDQaqlWrpq1z5MgREhIStHX27duHr68vjo6O6Y5Fkg8hhBBC35KGXbJ6y4Do6GiCg4MJDg4G4O7duwQHB/PgwQMSEhL46KOPOHv2LGvXriUxMZHQ0FBCQ0O1F8Hz8/OjcePG9OnTh9OnT3P8+HEGDBhAx44d8fDwAKBz586Ym5vTq1cvrly5woYNG5g7dy5Dhw7NUKwy7CKEEELoWyYWCUtxHxlw9uxZ6tWrp72flBB069aNCRMmsG3bNgAqVKig87iDBw8SEBAAwNq1axkwYAD169fHxMSEdu3aMW/ePG1de3t79u7dS//+/alcuTIuLi6MGzcuQ6fZgiQfQgghhFEICAhAUZRUt6e1LYmTkxPr1q1Ls065cuU4evRohuN7myQfQgghhL4ZYJGxvESSDyGEEELfDDDskpdI8iGEEELom/R8pMl40yohhBBC5ErS8yGEEELomwy7pEmSDyGEEELfVCo9JB/GO+wiyUc2qVmxOAO7NKB8ySIULGBP4PCl7Dp8CQAzUxPGfN6CD2uVxquQM+roWA6fvsbEBdsIffocAM+CTozo1Zi677+Hq7MdoU+fs3H3GWYu/52E14kABPVpypd9myY79stXcRSuOyznGvv/Zvy4m5nL9+iUFS/iyrH1owFY89sJtuw7x+XrIUTHxHFtz1TsbfPneJxZMX/1PqYs3kHvDv5MHtJWZ5uiKAQOW8LBP6+yfGovmviXM1CU73biwi0W/LSf4GsPCHuqZvW03jTzL6/dvv1gMCs3H+fitQc8U8dwaE0QZd8rbMCIs2b2yr1M+n4bn3UMYOqwjwwdjl4YU5uWbTzM/J/2Ex6hpoxPIb4b0Z7Kpb0NHZbIRpJ8ZJP8Vhb8deMfftp2kp+m6y6+kt/SnHIlPZn+427+uvkPDrb5mTrsI9bN/JQPuk0D4D1vN0xMTPhi6s/cefiEUsU9mPNVJ/JbWTBu7hYAFvz0Bys2655rvXXhIC78fT9nGpkC36LubJzbX3vf1PTfzP9VbDz1qpWkXrWSTFm8wxDhZUnw3/dZ89sJSpXwSHH70g2H8swPlZhXcZT2KUTnFtXpFvRDCtvjqV6+GK0bVGTIlPUGiFB/zl+5z8otxyntU8jQoeiNMbVp895zjJmzhVlffkzlMt4sXn+QdgO/58yv4yjgZGvo8DLPRPXmltV9GClJPrLJHyf+5o8Tf6e4Tf0ylrYDFuiUjZy+kQOrRlLYzZGHYc/Yf/Iq+09e1W6//08EJYq40vOjOtrk4+WreF6+itfWKeNTCL9iBRk29edsaFH6mJma4uqc8gWQ+n4cAMCJ8zdzMCL9eBkTR/+Ja5jxZUfmrNybbPtfNx6yZP1B9iwfTvkWYw0QYcY0qFmaBjVLp7r946ZVAXjwKCKnQsoW0TFx9B23krlfdWLGf3rl8ipja9PCdQfo2romgS1rADBrVEf2Hr/CT9tO8kX3hgaOLgtkzkeajKplAQEBDBo0iJEjR+Lk5IS7uzsTJkwA3qxH//HHH+vUT0hIwMXFhdWrVxsgWl12NlZoNBqeR79Ks86z5zGpbu/SqiY374dxMvh2doSYLncePqFCy7FUaz+JfhNW8zA00mCx6NOomb9Qv2Yp6lbxTbYtJjaefhNWM2VY+1QTL2EYI6ZtoGGtMgRUK2noUPTGmNoUn/Ca4GshBFT99+/KxMQE/6q+nLl814CRiexmVMkHwKpVq7C2tubUqVNMmzaNSZMmsW/fPgIDA9m+fTvR0dHaur///jsxMTG0adPGgBGDhbkZEwa0YtPec7x4GZtinaKFXej7sT8rtxxLdR/tG7/PT7+dzM5Q01SxlBdzR3dm3azP+HZ4e0IeR9C63zyiU2lTXrF133kuX3/IV5+1SHH7+LlbqFK2KI3rls3hyERaNu09y8VrIYzr39LQoeiNsbUpIiqaxERNsuGVAk52hEeoDRSVnhjgwnJ5idENu5QrV47x48cD4OPjw4IFC9i/fz9ff/011tbWbNmyhS5dugCwbt06WrZsia1tyuOKcXFxxMXFae+r1fr/YzAzNWHF1F6oVCqGfbshxToFC9jz67z+bP3jAqu3nkixTvOA8thYW7J+5ym9x5he9WuU0v6/VIlCVCrlRZV2E9l24AKdW9QwWFxZ8U/YM8bO2cSGuf2wtMiXbPvvRy9z/NwN9q0caYDoRGoehj5j1MxNbF4wIMXXLS8yxjYZNRl2SZNRJh9vK1iwIOHh4ZiZmdGhQwfWrl1Lly5dePnyJb/99hs//5z6/IipU6cyceLEbIs1KfHwdHekZb/5KfZ6uLvYs23RYE5fupPmxL8urWvy+9G/eBL5ItvizSh72/wU8yzA3YdPDR1Kpl26FsLTZ9E07DFDW5aYqOHP4Nus2HSUbm1qce+fCHwbfanzuN6jl1OtfHE2fz8wp0MWwMVrD3gS+YKALt9pyxITNZy4cJtlvxwh7PgcncnQeYExtsnZwQZTU5Nkn1tPItUyhGnkjC75yJdP9xeBSqVCo9EAEBgYiL+/P+Hh4ezbtw8rKysaN26c6r5GjRqlvSQxvOn58PT01EucSYlH8SIFaPHZPJ49f5msTsECbxKPi9ce0H/ST6lekbCIhzN1KvvQedhSvcSmLy9j4rj/TwQfNc67HyJ13n+Pg2uCdMqGfLOOEl5uDPikPk4ONnRpVVNne70u3zFxUBsa1i6Tk6GKt9St4svx9V/plA2Y9BM+3m4M7vphnvuSBuNsk3k+MyqU9OTwmes0C3hzqrdGo+HImRv0bl/XwNFlkSyvniajSz7SUrNmTTw9PdmwYQO7d++mffv2yZKVt1lYWGBhYZGpY1lbmVPUs4D2vpeHM2XeK0TU8xhCnz5n1Xe9KV/Sk45fLMbUVIWr85uhn2fPY0h4nUjBAvZsXzyYkNBIxs7dgoujjXZf4RG6vxI+aVmd0Kdq9p24kqlY9WXigq18WKsMnu6OhD5VM+OHXZiYqmjdoDIA4RFqwiPU2p6Qq7cfY5PfgkLujjjaWRsy9FTZWFtSsrjuqbX5rSxwtLfWlqf0C62QmyNFPJxzJMbMiI6J4+7DJ9r7Dx5FcPnGQxzt8lPY3Ylnz1/yMOwZoU/erDtz634Y8KatbnngF6mttWWyU6LzW5njZG+d6qnSuZ0xtgmgX+cP6DdxDRX9ilCptDeL1h/k5as4AltUN3RoWSPDLmn6n0o+4M1ZL4sXL+bGjRscPHgw245Twc+LHUsGa+9PGdoOgHU7/uTbpbto+v8LUB1dN0rncc0/ncvx8zcJqFaS4kVcKV7Elb93faNTx7HKAO3/VSoVnZtXZ/2OU2g0KfeM5JTH4VH0G7+KZ+qXODvYULVcMXYuGapNnFZvPa6zCFmb/vMAmPNVZz5uVs0gMf+vCr76gFb95mnvj5nz5vTtjs2q8v24Luw+epmBk9dqt/cesxKAkb2bENQn+cJ2QmRW24aVeRoVzZQlOwmPeEHZ9wrx67z+eX/YRXo+0qRSUuvLz4MCAgKoUKECc+bM0Za1bt0aBwcHVq5cCcDVq1cpVaoUXl5e3L17F1UGXly1Wo29vT0WZfugMjXXc/SG8/j4XEOHoH9G9jdrnge71N/FxIgXUBK5l1qtxs3ZnufPn2Nnp/8ER/s98cFkVGaWWdqX8jqWuANjsy1WQzKqno9Dhw4lK9u6davOfT8/v1TnTgghhBB6IcMuaTKq5EMIIYTIFWTYJU3Gm1YJIYQQIleSng8hhBBC7/Qw7GLE/QOSfAghhBD6JsMuaTLetEoIIYQQuZL0fAghhBD6plLp4WwX4+35kORDCCGE0Dc51TZNxtsyIYQQQuRK0vMhhBBC6JtMOE2TJB9CCCGEvsmwS5ok+RBCCCH0TXo+0mS8aZUQQgghciXp+RBCCCH0TYZd0iTJhxBCCKFvMuySJuNNq4QQQgiRK0nPhxBCCKFnKpUKlfR8pEqSDyGEEELPJPlImwy7CCGEECJHSc+HEEIIoW+q/79ldR9GSpIPIYQQQs9k2CVtknxkwsUdU7C1szN0GHoT91pj6BD0zsbSuN7aJibG+yEkhPjfY1yf0EIIIUQuID0faZPkQwghhNAzST7SJsmHEEIIoWeSfKRNTrUVQgghRI6Sng8hhBBC3+RU2zRJ8iGEEELomQy7pE2GXYQQQgiRo6TnQwghhNAzlQo99HzoJ5bcSJIPIYQQQs9U6GHYxYizDxl2EUIIIUSOkuRDCCGE0LOkCadZvWXEkSNHaNGiBR4eHqhUKrZu3aqzXVEUxo0bR8GCBbGysqJBgwbcvHlTp05kZCSBgYHY2dnh4OBAr169iI6O1qlz6dIl6tSpg6WlJZ6enkybNi3Dz48kH0IIIYS+qfR0y4CXL19Svnx5vv/++xS3T5s2jXnz5rF48WJOnTqFtbU1jRo1IjY2VlsnMDCQK1eusG/fPnbs2MGRI0fo27evdrtaraZhw4Z4eXlx7tw5pk+fzoQJE1i6dGmGYpU5H0IIIYQRaNKkCU2aNElxm6IozJkzhzFjxtCqVSsAVq9ejZubG1u3bqVjx45cvXqVPXv2cObMGd5//30A5s+fT9OmTZkxYwYeHh6sXbuW+Ph4li9fjrm5OaVLlyY4OJhZs2bpJCnvIj0fQgghhL7pY8jl/4dd1Gq1zi0uLi7D4dy9e5fQ0FAaNGigLbO3t6datWqcPHkSgJMnT+Lg4KBNPAAaNGiAiYkJp06d0tapW7cu5ubm2jqNGjXi+vXrPHv2LN3xSPIhhBBC6Jk+53x4enpib2+vvU2dOjXD8YSGhgLg5uamU+7m5qbdFhoaiqurq852MzMznJycdOqktI+3j5EeMuwihBBC6Jk+VjhNenxISAh2dnbacgsLiyztNzeQng8hhBAiF7Ozs9O5ZSb5cHd3ByAsLEynPCwsTLvN3d2d8PBwne2vX78mMjJSp05K+3j7GOkhyYcQQgihbwY42yUtRYsWxd3dnf3792vL1Go1p06dokaNGgDUqFGDqKgozp07p61z4MABNBoN1apV09Y5cuQICQkJ2jr79u3D19cXR0fHdMcjyYcQQgihZ4ZY5yM6Oprg4GCCg4OBN5NMg4ODefDgASqViiFDhvD111+zbds2Ll++TNeuXfHw8KB169YA+Pn50bhxY/r06cPp06c5fvw4AwYMoGPHjnh4eADQuXNnzM3N6dWrF1euXGHDhg3MnTuXoUOHZihWmfMhhBBCGIGzZ89Sr1497f2khKBbt26sXLmSkSNH8vLlS/r27UtUVBS1a9dmz549WFpaah+zdu1aBgwYQP369TExMaFdu3bMmzdPu93e3p69e/fSv39/KleujIuLC+PGjcvQabYAKkVRlCy2N88KCAigQoUKzJkzJ1311Wo19vb2XLv/BNu3Jv+k1+mLt1m24SB/3XhIeISaRZN70LB2We12RVGYs2IPG3b+iTr6FZXLFGXSFx9RtHABAP4MvkXgFwtT3PeWRUMoV7JIhmMCMDXRX99edEwsM3/czd6jl3n6LJrSPoUYP7AN5f2Sx/bVzI2s23aSsQNa06u9v95iALCx1F9efeLCLRb8tJ+L1x4Q9lTN6mm9aepfXrs9OiaOyd//xq7Dl3mmfkmRgs70+difHm1r6y0Gfb5G/zVrxe/sOHiRm/fDsLTIR9VyxZgwoBU+3m7vfnAuZYxtSrJs42Hm/7Sf8Ag1ZXwK8d2I9lQu7W3osLIkJ9ukVqtxc7bn+fPnOpM49bl/e3t7CnRdhYl5/iztSxMfw5PV3bItVkOSYZccFBMbT8niHkwY3DbF7Ut/PsCqzUeZ/EV7Ni8cQn5Lc3qMXEJc/JuxtUqlvflz0wSdW4dm1fAs6ERZX8+cbEqqgqZt4NjZ68waHcjvK0ZQp4ovnwxbROiTKJ16e45c4sLf93FzsTdMoBkQ8yqOMj6FmDaiQ4rbx87ZzIE/r7JoYldO/DyaTzsG8OWMX9h95HIOR5o5J87fonf7uuxdPpzNCwaQ8DqRtgMX8PJVxtcSyC2MsU0Am/eeY8ycLQT1bsKhNUGU8SlEu4Hf8yTyhaFDyzRjbBMYZtglL5HkIwcFVPNjWK+mNKpTLtk2RVFY8esR+nf5kA9rl6FkcQ9mjOpM2FM1e4/9BYB5PjMKONlpbw521vxx/ArtGlfNFW/S2Lh49hy5xKjPWlCtfHG8Cxfgix6N8Srkwk+/ndDWC30SxYR5m5k75hPMzHL/W7BBzdJ89VlzmgWUT3H7mct3+bhpNWpX9qGIhzPd2tSidIlCXPj7fg5Hmjm/zu9P5xbV8StekLLvFWbh+E94GPqM4Kshhg4t04yxTQAL1x2ga+uaBLasQcliBZk1qiP5Lc35adtJQ4eWacbYJvFuuf+T//8FBAQwcOBAhgwZgqOjI25ubixbtoyXL1/So0cPbG1tKVGiBLt379Y+5q+//qJJkybY2Njg5uZGly5dePr0qQFbkbqQx5E8iXxBrcrvactsbayo4FeEC1fupfiY/cf/Ikr9ko+aVM2hKNP2OlFDYqIGC/N8OuWWFvk4c/kOABqNhi++WUvfjvV4r2hBQ4Spd1XKFmXP0cs8Do9CURSOnr3B7ZBwAqqVNHRomaKOfnOdB0e7rHUZ5ybG0Kb4hNcEXwshoKqvtszExAT/qr6cuXzXgJFlnjG2KYn0fKQtzyQfAKtWrcLFxYXTp08zcOBAPv/8c9q3b0/NmjU5f/48DRs2pEuXLsTExBAVFcUHH3xAxYoVOXv2LHv27CEsLIwOHVLuOk9JXFxcsmVts8uTyDf7dnG01Sl3cbRNtftx4+5T1KniS8ECDtkWV0bY5LekUmlv5q3eS9jT5yQmatiy9yznr9zjScSb9i1adwAzUxN6tKtr4Gj159vhH+Fb1J2yLcZSsNYQPh6yiGkj2lOzYglDh5ZhGo2GUbN+pVr5YpQq4WHocPTCWNoUERVNYqKGAk66nxEFnOwIj8i+z6bsZIxt0splp9rmNnnqbJfy5cszZswYAEaNGsW3336Li4sLffr0AWDcuHEsWrSIS5cu8ccff1CxYkWmTJmiffzy5cvx9PTkxo0bvPfeeyke421Tp05l4sSJ2dOYLHr8JIqjZ64zf1xXQ4eiY/boQEZ89zPV2k3A1NSEMj6FaVm/Epevh3D5eggrNh1h57JhRpXRL9t4hLN/3eOnGX3xdHfiZPAtRk7/BXcXe/yr5q3ej+HTNnL19mN2L/vC0KHojTG2SYi8Lk8lH+XK/TtXwtTUFGdnZ8qW/fdskaT15cPDw7l48SIHDx7ExsYm2X5u376druRj1KhROucuq9VqPD2zZ2JnAac3M5mfPnuBq/O/s5qfPnuBX4lCyer/uvs0DnbW1K9VJlviySyvQi5snDeAmFdxRMfE4upsT/8Jqyji4czpS3eIeBZNzQ6TtPUTEzV8s/A3lv96mOMbxhkw8sx5FRvPN4u2s+q73jSs/ea1KO1TiMs3/uH7tQfyVPIxYtpGfj/6F7uWDqGQW/oXC8rNjKlNzg42mJqaJOsJfRKp1vnMyEuMsU1J9Lm8ujHKU8lHvny6cwlUKpVOWdILpdFoiI6OpkWLFnz33XfJ9lOwYPrmGlhYWOTYGvqeBZ0o4GTLifM3KfX/ycaLl7EEX31A51a1dOoqisKmPadp0/B98pmZ5kh8GZXfyoL8VhY8fxHDkTPXGPVpC5r4l6d2Zd2kr+uIJbRpWJn2TaoZKNKsef06kYTXiZj851RYUxMTNJq8cRa7oiiMnP4LOw9dZPviwXgVcjF0SFlmjG0yz2dGhZKeHD5zXTv5WaPRcOTMDXq3z5vDmMbYpiSSfKQtTyUfGVGpUiU2bdqEt7c3Zma5o5kvX8Vx/59/J7w+fBzJ37f+wcE2Px5ujvT4qC7fr9mHdyEXPAs6MWv5Htxc7LS/qJOcOH+TkMeRfNws931hHz59DUVRKF7ElXsPnzJl8TaKF3GjfdNq5DMzxdHeWqe+mZkJBZzsKF7ENZU9Gl50TBx3Hz7R3r//KILLNx7iaJefwu5O1KxUggnzf8PSwhzPgo6cOH+LjbtPM2lwGwNGnX7Dv9vIr7+fZd2MvtjktyTs6ZuxdjsbS6wszd/x6NzJGNsE0K/zB/SbuIaKfkWoVNqbResP8vJVHIEtqhs6tEwzxjaBJB/vkju+lbNB//79WbZsGZ06dWLkyJE4OTlx69Ytfv75Z3744QdMTXO+x+Dy9RCdRcK+WfgbAG0bVWH6l53o2/EDYl7FM3rmL6ijX/F+2aKs+K5vsrNHftl1ikqlvSleJPctmPQi+hXTlu0k9EkU9rb5aeJfnuG9m+baHpr0CL76gNb9/l3hb+ycLQB0bFaVBeO6sOzrHnz9/TY+G7+KKHUMhd0d+eqz5npdZCw7Ld90FIDmn83VKf9+3Cd0zqNfAMbYJoC2DSvzNCqaKUt2Eh7xgrLvFeLXef3z9BCFMbZJvFueWeE0pdVIvb29GTJkCEOGDNGWqVQqtmzZQuvWrbl58yZBQUEcPHiQuLg4vLy8aNy4MbNmzUKlUuX4Cqe5VXaunmko+lzhNDcwxtdICEPIqRVOPfqs08sKp4+WdTbKFU7zzCf0oUOHkpXdu3cvWdnbuZSPjw+bN2/O0D6FEEKIrJJhl7TlqXU+hBBCCJH35ZmeDyGEECKvkJ6PtEnyIYQQQuiZCj0kH0a8xKkMuwghhBAiR0nPhxBCCKFnMuySNkk+hBBCCH3Tx4XhjDf3kGEXIYQQQuQs6fkQQggh9EyGXdImyYcQQgihZ5J8pE2SDyGEEELPVKo3t6zuw1jJnA8hhBBC5Cjp+RBCCCH07E3PR1aHXfQUTC4kyYcQQgihb3oYdpFTbYUQQggh9ER6PoQQQgg9k7Nd0ibJhxBCCKFncrZL2mTYRQghhBA5Sno+hBBCCD0zMVFhYpK1rgsli4/PzST5EEIIIfRMhl3SJsMuQgghhMhR0vORCeZmJpibGU/eZpnPeNqS5MWrBEOHoFd2VvkMHYJIh6x2swvjIWe7pE2SDyGEEELPZNglbZJ8CCGEEHomPR9pM77+diGEEELkatLzIYQQQuiZ9HykTZIPIYQQQs9kzkfaZNhFCCGEEDlKej6EEEIIPVOhh2EXjLfrQ5IPIYQQQs9k2CVtMuwihBBCiBwlPR9CCCGEnsnZLmmT5EMIIYTQMxl2SZsMuwghhBAiR0nPhxBCCKFnMuySNkk+hBBCCD2TYZe0SfIhhBBC6Jn0fKRN5nwIIYQQIkdJz4cQQgihb3oYdjHiBU6l50MIIYTQt6Rhl6zeMiIxMZGxY8dStGhRrKysKF68OJMnT0ZRFG0dRVEYN24cBQsWxMrKigYNGnDz5k2d/URGRhIYGIidnR0ODg706tWL6OhovTwvSST5EEIIIYzAd999x6JFi1iwYAFXr17lu+++Y9q0acyfP19bZ9q0acybN4/Fixdz6tQprK2tadSoEbGxsdo6gYGBXLlyhX379rFjxw6OHDlC37599RqrDLsYUI32E3kY+ixZedc2tflm6Ee0HzifP4Nv62z7pFVNpg7vkFMhZsicVXvZeegSN++HYWWRjyplizKuf0tKeLnp1Dtz+S5TFu/g/JX7mJioKPNeYTbO+RwrS3MDRZ626JhYZv24m9+P/UXEsxeU9inMuIGtKV+yCABFA4am+LgvP2vOpx0/yMlQ0+3EhVss+Gk/wdceEPZUzeppvWnmX167ffvBYFZuPs7Faw94po7h0Jogyr5X2IARp+1d7VEUhW+X7mLNbyd4Hv2KquWKMmPkxxQv4mrAqDPu+PlbzF/zBxevPSD0qZqfpvehWUD5dz8wl1u28TDzf9pPeISaMj6F+G5EeyqX9jZ0WFliiLNdTpw4QatWrWjWrBkA3t7erF+/ntOnTwNv/g7mzJnDmDFjaNWqFQCrV6/Gzc2NrVu30rFjR65evcqePXs4c+YM77//PgDz58+nadOmzJgxAw8Pj6w16v/l6Z6PgIAAhgwZkup2b29v5syZk+nHZ7cdS4dxbusk7W3d7M8BaF7v3w+Tzi1q6NT56vOWhgr3nU5cuEXPdnXY88NQfpnXn4TXibQfvJCXr+K0dc5cvsvHQxYRUK0kvy8fxr4Vw+n1UR1MTHLv4OaX0zdy7NwNZn3VmT3LR1Dn/ffoMmwxoU+iADi9aYLObVpQR1QqFU3q5t4vhZhXcZT2KcS0ESknsjGv4qlevhjjB7TK4cgy513tmbfmD5ZuPMyMoI/Z++Mw8lta0H7wQmLjEnI40qyJeRVHmfcKMX3kx4YORW827z3HmDlbCOrdhENrgijjU4h2A7/nSeQLQ4eWJYYYdqlZsyb79+/nxo0bAFy8eJFjx47RpEkTAO7evUtoaCgNGjTQPsbe3p5q1apx8uRJAE6ePImDg4M28QBo0KABJiYmnDp1KqtPi5b0fBiQs6ONzv2Fa//Aq5AL1SuU0JZZWebD1dkup0PLlI1z+uncnz82EL8mo7l4LYSaFd+0aeyczfTp4M/grh9q6/23ZyQ3iY2LZ8/hSyz9pifVyhcHYEiPxuw/+Tc//XaC4b2bUuA/r8++Y39Ro2IJing4GyLkdGlQszQNapZOdfvHTasC8OBRRE6FlCVptUdRFJb8fIhhPRrR1L8cAIsmdKFkk6/YdfgSbRtWzslQs+TDWqX5sFbqr1tetHDdAbq2rklgyxoAzBrVkb3Hr/DTtpN80b2hgaPLHdRqtc59CwsLLCwsktX78ssvUavVlCxZElNTUxITE/nmm28IDAwEIDQ0FAA3N93PXDc3N+220NBQXF11ewTNzMxwcnLS1tGHPN3zYUziE16zee85Pm5aTSfb3bL3HOWaj6Z+12/5dvF2XsXGGzDKjFFHvxlDdLTLD8CTyBecu3IfF0cbmvaZRakmo2n5+dxkQ0u5yetEDYkaDRbmunm6pXk+zl6+m6z+k8gXHPzzbzr8/5e3MLz7jyIIi1DjX9VXW2ZnY0Xl0t6cSeE1FDknPuE1wddCCHjrtTExMcG/qm+ef22Shl2yegPw9PTE3t5ee5s6dWqKx9y4cSNr165l3bp1nD9/nlWrVjFjxgxWrVqVgy1PnzyffLx+/ZoBAwZgb2+Pi4sLY8eO1ZnZ+7YffvgBBwcH9u/fn8NRvtvvRy+jjn5F+7e+tFp/WJm5Yz9hw9z+DPikAZv2nmXQ5J8MGGX6aTQaxszZTNVyxfAr/maM8P6jpwBM/2E3n7Sqyc9zPqOcryftBi7g9oNwQ4abKpv8llQq7c381fsIe/qcxEQNW/ae5fzf9wiPVCerv+n3M1jnt6BxnXIGiFakJDzizetUwMlWp7yAk22Kr6HIORFR0SQmalJ4bey0r1tepc9hl5CQEJ4/f669jRo1KsVjjhgxgi+//JKOHTtStmxZunTpwhdffKFNVtzd3QEICwvTeVxYWJh2m7u7O+Hhup/Hr1+/JjIyUltHH/J88rFq1SrMzMw4ffo0c+fOZdasWfzwww/J6k2bNo0vv/ySvXv3Ur9+/XTtOy4uDrVarXPLLj/v+JN61fxwd7HXlgW2rElANT/8invQpuH7zBkdyJ4jl7j3z9Nsi0Nfgqb/wrXbj1n2dTdtmUbzJins2qYWnZtXp5yvJ18PaUuJIm6s2/GnoUJ9p1lfdUZBofpHE/H9cCQrNx+lxQcVMUlhPPaXXadp1aAyFhb5DBCpEMIY2dnZ6dxSGnIBiImJwcRE92vd1NQUjUYDQNGiRXF3d9f5Aa5Wqzl16hQ1arwZ9qpRowZRUVGcO3dOW+fAgQNoNBqqVaumtzbl+Tkfnp6ezJ49G5VKha+vL5cvX2b27Nn06dNHWycoKIg1a9Zw+PBhSpdO/3jp1KlTmThxYnaEreNhaCTHzt1g6dc906xXsZQXAPcePsG7kEu2x5VZQTN+Ye/xK2xbPBgPV0dtudv/J1a+3rrZs4+3G/+kcNZPbuFVyIUNcwcQ8yqO6Jg4XJ3tGDBxdbI5Hacv3eFOSDjzx3cxUKQiJUlzpp5EvtBJ7p9EvqCMTyFDhSUAZwcbTE1Nkk0ufRKpzjNz3VJjiOXVW7RowTfffEORIkUoXbo0Fy5cYNasWfTs2VO7vyFDhvD111/j4+ND0aJFGTt2LB4eHrRu3RoAPz8/GjduTJ8+fVi8eDEJCQkMGDCAjh076u1MFzCCno/q1avrvEA1atTg5s2bJCYmAjBz5kyWLVvGsWPHMpR4AIwaNUqnqyskJESvsSfZuOsULg621K9RKs16V27+A4Cbs32a9QxFURSCZvzCrsOX2LxgAF7/+XIuUtAJ9wL23PrPEMvtkHAKF3TKyVAzJb+VBa7Odjx/EcOR09doUKuMzvaNO09R9r3ClCohX2i5iZeHM27Odhw5c11bpo5+xbkr96hStqgBIxPm+cyoUNKTw2+9NhqNhiNnbuT510afcz7Sa/78+Xz00Uf069cPPz8/hg8fzqeffsrkyZO1dUaOHMnAgQPp27cvVapUITo6mj179mBpaamts3btWkqWLEn9+vVp2rQptWvXZunSpfp6agAj6Pl4lzp16rBz5042btzIl19+maHHpjajWJ80Gg0bd53moyZVMDMz1Zbf++cpW/ed44MapXC0y8/V24+ZOH8L1coXx6+E/rJPfQqa/gub9p5j9bTe2FhbEvb/Y7Z21pZYWZqjUqnoH/gB05btprSPB2V8CrNh12lu3Q9n+ZS0e30M6fDpa6AoFCviyr1/njJ10XaKF3GlfZN/5+e8eBnLrsMXGZ2LT4V+W3RMHHcfPtHef/Aogss3HuJol5/C7k48e/6Sh2HPCH3yHIBb99+MEbs62+GWC3+Rvqs9n3YMYOaK3ynm6YqXhzNTluzA3cVee/ZLXhEdE8fdkH/bef9RBJevP8TBPj+e7rk/gU9Jv84f0G/iGir6FaFSaW8WrT/Iy1dxBLaobujQssQQPR+2trbMmTMnzSUmVCoVkyZNYtKkSanWcXJyYt26dRk6dkbl+eTjv+cd//nnn/j4+GBq+uaLvGrVqgwYMIDGjRtjZmbG8OHDDRFmqo6evcE/Yc/4uKnuWJq5mSnHzt7gx18O8yo2noKuDjT1L8+gbrn31LMVm48B0LrffJ3yeWMC6dT8Tfs+61iPuPjXjJ2zhSh1DKV9PPhlbj+KFi6Q4/Gm14uXsUxftpPQJ1HY2+ancd1yDO/dlHxvJYvbD1xAURRa1K9owEjTL/jqA1r1m6e9P2bOFgA6NqvK9+O6sPvoZQZOXqvd3nvMSgBG9m5CUJ+mORpreryrPYO6NCDmVTxDp67nefQrqpUvxsa5/bDMY3Nzgq/ep8Vn/7Zz9OzNAHRqVo2FE/LmcF/bhpV5GhXNlCU7CY94Qdn3CvHrvP55fthFpE2lpHZqSB4QEBDAuXPn6NOnD59++innz5+nT58+zJw5k08//RRvb2+GDBnCkCFDtAutTJ48WbuwWEBAABUqVEgzS3ybWq3G3t6eO/9EYGtnPH8Ylvny/OhbMtGxrw0dgl7ZWeWtL8n/Vbl5sTzxhlqtxs3ZnufPn2OXDZ/jSd8Ttb/di5mldZb29Tr2Jce+bJhtsRpSnu/56Nq1K69evaJq1aqYmpoyePDgFNegr127Njt37qRp06aYmpoycOBAA0QrhBDif4Ehhl3ykjydfBw6dEj7/0WLFiXbfu/ePZ37devW1bky39uPF0IIIUTOyNPJhxBCCJEbqdDDheX0EknuJMmHEEIIoWcmKlWKCxFmdB/GyvhmGgohhBAiV5OeDyGEEELPMrNIWEr7MFaSfAghhBB6Jme7pE2SDyGEEELPTFRvblndh7GSOR9CCCGEyFHS8yGEEELom0oPwyZG3PMhyYcQQgihZzLhNG0y7CKEEEKIHCU9H0IIIYSeqf7/X1b3Yawk+RBCCCH0TM52SZsMuwghhBAiR0nPhxBCCKFnsshY2tKVfGzbti3dO2zZsmWmgxFCCCGMgZztkrZ0JR+tW7dO185UKhWJiYlZiUcIIYQQRi5dyYdGo8nuOIQQQgijYaJSYZLFrousPj43y9Kcj9jYWCwtLfUVixBCCGEUZNglbRk+2yUxMZHJkydTqFAhbGxsuHPnDgBjx47lxx9/1HuAQgghRF6TNOE0qzdjleGej2+++YZVq1Yxbdo0+vTpoy0vU6YMc+bMoVevXnoNMDeyyGeCZT7jOUvZzNR42pLE1iqfoUPQq/jXxjf0aWFEf0NCiIzJ8F//6tWrWbp0KYGBgZiammrLy5cvz7Vr1/QanBBCCJEXJQ27ZPVmrDLc8/HPP/9QokSJZOUajYaEhAS9BCWEEELkZTLhNG0Z7vkoVaoUR48eTVb+66+/UrFiRb0EJYQQQgjjleGej3HjxtGtWzf++ecfNBoNmzdv5vr166xevZodO3ZkR4xCCCFEnqL6/1tW92GsMtzz0apVK7Zv384ff/yBtbU148aN4+rVq2zfvp0PP/wwO2IUQggh8hQ52yVtmVrno06dOuzbt0/fsQghhBDif0CmFxk7e/YsV69eBd7MA6lcubLeghJCCCHyMhPVm1tW92GsMpx8PHz4kE6dOnH8+HEcHBwAiIqKombNmvz8888ULlxY3zEKIYQQeYpc1TZtGZ7z0bt3bxISErh69SqRkZFERkZy9epVNBoNvXv3zo4YhRBCCGFEMtzzcfjwYU6cOIGvr6+2zNfXl/nz51OnTh29BieEEELkVUbccZFlGU4+PD09U1xMLDExEQ8PD70EJYQQQuRlMuyStgwPu0yfPp2BAwdy9uxZbdnZs2cZPHgwM2bM0GtwQgghRF6UNOE0qzdjla6eD0dHR50M7OXLl1SrVg0zszcPf/36NWZmZvTs2ZPWrVtnS6BCCCGEMA7pSj7mzJmTzWEIIYQQxkOGXdKWruSjW7du2R2HEEIIYTRkefW0ZXqRMYDY2Fji4+N1yuzs7LIUkBBCCCGMW4aTj5cvXxIUFMTGjRuJiIhItj0xMVEvgQkhhBB5lYlKhUkWh02y+vjcLMNnu4wcOZIDBw6waNEiLCws+OGHH5g4cSIeHh6sXr06O2IUQggh8hSVSj83Y5Xhno/t27ezevVqAgIC6NGjB3Xq1KFEiRJ4eXmxdu1aAgMDsyNOIYQQQhiJDPd8REZGUqxYMeDN/I7IyEgAateuzZEjR/QbnRBCCJEHJZ3tktWbscpwz0exYsW4e/cuRYoUoWTJkmzcuJGqVauyfft27YXmRPrMWbWXnYcucfN+GFYW+ahStijj+rekhJebtk6rz+dx4sItncd1a1OLGUEf53S4mXL8/C3mr/mDi9ceEPpUzU/T+9AsoLyhw8qQExduseCn/Vy89oCwp2pWT+tNU/9/2+BSbWCKjxs/oBUDuzTIqTDTbcaPu5m5fI9OWfEirhxbPxqANb+dYMu+c1y+HkJ0TBzX9kzF3ja/IULNtMREDd8u28Uvu88QHvkCdxd7OjWvxvCejfL0B7ox/D2lZNnGw8z/aT/hEWrK+BTiuxHtqVza29BhZYk+hk3y8Fv1nTKcfPTo0YOLFy/i7+/Pl19+SYsWLViwYAEJCQnMmjUrO2LUCggIoEKFCkaz7siJC7fo2a4OFUsV4XWihm8Wbaf94IUcW/8V1lYW2npdWtUkqG9T7f38lvkMEW6mxLyKo8x7hfikZQ26jFxm6HAyJeZVHGV8ChHYojrdgn5Itv3Krm907u8/8TeDv1lHiw8q5FCEGedb1J2Nc/tr75ua/tsJ+io2nnrVSlKvWkmmLN5hiPCybO7qfazYdIyF4z+hZLGCXLj6gIGT12JnY8mnHwcYOrxMM4a/p//avPccY+ZsYdaXH1O5jDeL1x+k3cDvOfPrOAo42Ro6PJFNMpx8fPHFF9r/N2jQgGvXrnHu3DlKlChBuXLl9Bqcsds4p5/O/fljA/FrMpqL10KoWbGEttzKMh9uznnzFOYPa5Xmw1qlDR1GljSoWZoGNVNvw39fm91HLlG7sg/ehVyyO7RMMzM1xTWV91Tf//9yPnH+Zg5GpF+nL92lSd2yNKxdBoAiHs5s2nuO81fuGziyrDGGv6f/WrjuAF1b1ySwZQ0AZo3qyN7jV/hp20m+6N7QwNFlnpztkrYsrfMB4OXlhZeXlz5i+Z+njo4FwNFOt4t70+9n+XXPWVyd7WhYuzTDejYmv6W5IUIU7xAeoWbf8SssGN/F0KGk6c7DJ1RoORYLi3xULu3NV581p7C7k6HD0puq5YqyausJbt0Pp4SXK3/deMipi3f4ekgbQ4cm3hKf8JrgayE6SYaJiQn+VX05c/muASPLOhl2SVu6ko958+ale4eDBg3KdDDp8fr1awYMGMCaNWvIly8fn3/+OZMmTUKlUhEXF8e4ceNYt24d4eHheHp6MmrUKHr16gXAlStXCAoK4siRIyiKQoUKFVi5ciXFixfP1pjTQ6PRMGbOZqqWK4Zf8X+vDtyuUWUKuzvh7mLP37f+YdL327h9P5yV3/U2YLQiNT/vOo2NtSXNc/E4fMVSXswd3ZniRVwJi1Aza/keWvebx6E1X2JjbWno8PRiSLcPefEylmodvsbUREWiRmHM581p37iKoUMTb4mIiiYxUZNseKWAkx0374UZKCr9kOXV05au5GP27Nnp2plKpcr25GPVqlX06tWL06dPc/bsWfr27UuRIkXo06cPXbt25eTJk8ybN4/y5ctz9+5dnj59CsA///xD3bp1CQgI4MCBA9jZ2XH8+HFev36d6rHi4uKIi4vT3ler1dnWrqDpv3Dt9mN2LB2sU961dS3t/0uV8MDNxZ62AxZw9+ETihYukG3xiMxZt/0kHzV6H0uL3Dsvp36NUtr/lypRiEqlvKjSbiLbDlygc4saBoxMf7b8cYFf9pxl6eRu+BUryOUbD/lq1ibtxFMhhGGlK/m4ezf3dH95enoye/ZsVCoVvr6+XL58mdmzZ+Pv78/GjRvZt28fDRq8OcMg6ZRggO+//x57e3t+/vln8uV788Xw3nvvpXmsqVOnMnHixOxrzP8LmvELe49fYdviwXi4OqZZt1LpN0Ncdx8+leQjlzl54Ra37ofzw9c9DB1Khtjb5qeYZwHuPnxq6FD0Zvy8rQzp9iHtGlYG3iTuIY8jmbNqryQfuYizgw2mpiY8iXyhU/4kUp3qnKS8woRMrGWRwj4y6p9//iEoKIjdu3cTExNDiRIlWLFiBe+//z4AiqIwfvx4li1bRlRUFLVq1WLRokX4+Pho9xEZGcnAgQPZvn07JiYmtGvXjrlz52JjY5PFFv0rq89NjqtevbpOV1SNGjW4efMmFy5cwNTUFH9//xQfFxwcTJ06dbSJR3qMGjWK58+fa28hISFZjv9tiqIQNOMXdh2+xOYFA/DycH7nY/668Q+QfJKjMLy1209SvqQnZd4rbOhQMuRlTBz3/4nAzcV43lOvYuOTTdYzNTVBo1EMFJFIiXk+MyqU9OTwmevaMo1Gw5EzN6hStqgBI8s6Q6zz8ezZM2rVqkW+fPnYvXs3f//9NzNnzsTR8d8ftdOmTWPevHksXryYU6dOYW1tTaNGjYiNjdXWCQwM5MqVK+zbt48dO3Zw5MgR+vbtq7fnBvQw4TS3sLRMe6zaysoqw/u0sLDAwsLi3RUzKWj6L2zae47V03pjY21JWMSbYR07a0usLM25+/AJm/eeo0HNUjjaWfP3rUeMnbuZGhWLU9qnULbFpU/RMXHcDXmivX//UQSXrz/EwT4/nnlkgmN0TBx3H/6nDTce4miXXztJ80X0K7btD2bi4Nw/oXHigq18WKsMnu6OhD5VM+OHXZiYqmjd4E0vQXiEmvAItbYn5Ortx9jkt6CQuyOOdtaGDD3dGtcpw8yVeyns7kjJYgW5dP0hC9cdJLBFdUOHliXG8Pf0X/06f0C/iWuo6FeESqW9WbT+IC9fxeX518oQvvvuOzw9PVmxYoW2rGjRf5M4RVGYM2cOY8aMoVWrVgCsXr0aNzc3tm7dSseOHbl69Sp79uzhzJkz2t6S+fPn07RpU2bMmIGHhwf6kOeSj1OnTunc//PPP/Hx8aF8+fJoNBoOHz6sHXZ5W7ly5Vi1ahUJCQkZ6v3ITis2HwOgdb/5OuXzxgTSqXk1zPOZcfjMdZb8fIiY2Hg8XB1pHlCBoT3zzulnwVfv0+Kzfycsj569GYBOzaqxcELuPiMkSfDVB7Tu928bxs7ZAkDHZlVZMO5NGzbvO4+iKNpu/tzscXgU/cav4pn6Jc4ONlQtV4ydS4bi4vimS3X11uM6i5C16f+m7XO+6szHzfLGkMW3w9szZclOhk/byNNn0bi72NO9TS1G9G5s6NCyxBj+nv6rbcPKPI2KZsqSnYRHvKDse4X4dV7/PD/solKBiZ7OdvnvfMPUfhhv27aNRo0a0b59ew4fPkyhQoXo168fffr0Ad5MoQgNDdX5jrS3t6datWqcPHmSjh07cvLkSRwcHLSJB7xZVsPExIRTp07Rpo1+fmCpFEXJM/2QAQEBnDt3jj59+vDpp59y/vx5+vTpw8yZM/n000/p0aMH+/fv1044vX//PuHh4XTo0IGIiAh8fX3x9/dn1KhR2Nvb8+eff1K1alV8fX3TdXy1Wo29vT3/hD/Dzi5v/2G8zcw0z42+vVOikXWvJ7zWGDoEvbPIZ3zvO2M+O8FYqNVq3Jztef78ebZ8jid9T/RbfwaL/FmbIxEXE83CTsnP0Bo/fjwTJkxIVp40AjB06FDat2/PmTNnGDx4MIsXL6Zbt26cOHGCWrVq8ejRIwoWLKh9XIcOHVCpVGzYsIEpU6awatUqrl+/rrNvV1dXJk6cyOeff56lNiXJcz0fXbt25dWrV1StWhVTU1MGDx6sHYtatGgRX331Ff369SMiIoIiRYrw1VdfAeDs7MyBAwcYMWIE/v7+mJqaUqFCBWrVqpXW4YQQQgiDCgkJ0UmUUpsOoNFoeP/995kyZQoAFStW5K+//tImH7lJppKPo0ePsmTJEm7fvs2vv/5KoUKFWLNmDUWLFqV27dr6jlHr0KFD2v8vWrQo2XZLS0tmzZqV6jLv5cqV4/fff8+u8IQQQghAv+t82NnZpauXpmDBgpQqVUqnzM/Pj02bNgHg7u4OQFhYmE7PR1hYGBUqVNDWCQ8P19nH69eviYyM1D5eHzLc77lp0yYaNWqElZUVFy5c0K6D8fz5c222JYQQQvwvM1Hp55YRtWrVSjZccuPGDe0q5EWLFsXd3Z39+/drt6vVak6dOkWNGm/W+KlRowZRUVGcO3dOW+fAgQNoNBqqVdPfnK8MJx9ff/01ixcvZtmyZToTN2vVqsX58+f1FpgQQggh0u+LL77gzz//ZMqUKdy6dYt169axdOlS+vd/cxFJlUrFkCFD+Prrr9m2bRuXL1+ma9eueHh40Lp1a+BNT0njxo3p06cPp0+f5vjx4wwYMICOHTvq7UwXyMSwy/Xr16lbt26ycnt7e6KiovQRkxBCCJGnGeLaLlWqVGHLli2MGjWKSZMmUbRoUebMmUNgYKC2zsiRI3n58iV9+/YlKiqK2rVrs2fPHp3lKtauXcuAAQOoX7++dpGxjFxmJT0ynHy4u7tz69YtvL29dcqPHTums6KoEEII8b/KUFe1bd68Oc2bN091u0qlYtKkSUyaNCnVOk5OTqxbty7Dx86IDA+79OnTh8GDB3Pq1ClUKhWPHj1i7dq1DB8+XG+n4AghhBB5mYmebsYqwz0fX375JRqNhvr16xMTE0PdunWxsLBg+PDhDBw4MDtiFEIIIYQRyXDyoVKpGD16NCNGjODWrVtER0dTqlQpvV5wRgghhMjLDDHnIy/J9CJj5ubmyc4nFkIIIQSYoIc5Hxhv9pHh5KNevXppLpxy4MCBLAUkhBBCCOOW4eQjaRW0JAkJCQQHB/PXX3/luuVbhRBCCEOQYZe0ZTj5mD17dorlEyZMIDo6OssBCSGEEHldZlYoTWkfxkpvZ/J88sknLF++XF+7E0IIIYSR0ttVbU+ePKmzQpoQQgjxv0qlytwiYf/dh7HKcPLRtm1bnfuKovD48WPOnj3L2LFj9RaYEEIIkVfJnI+0ZTj5sLe317lvYmKCr68vkyZNomHDhnoLTAghhBDGKUPJR2JiIj169KBs2bI4OjpmV0xCCCFEniYTTtOWoQmnpqamNGzYUK5eK4QQQqRBpad/xirDZ7uUKVOGO3fuZEcsQgghhFFI6vnI6s1YZTj5+Prrrxk+fDg7duzg8ePHqNVqnZsQQgghRFrSPedj0qRJDBs2jKZNmwLQsmVLnWXWFUVBpVKRmJio/yhzGRNV1tfsz00URTF0COIdzM2M7+LaiRrje9+ZmRrP54LIGpnzkbZ0Jx8TJ07ks88+4+DBg9kZjxBCCJHnqVSqNK+Dlt59GKt0Jx9Jv479/f2zLRghhBBCGL8MnWprzFmYEEIIoS8y7JK2DCUf77333jsTkMjIyCwFJIQQQuR1ssJp2jKUfEycODHZCqdCCCGEEBmRoeSjY8eOuLq6ZlcsQgghhFHQx1mRxnRW5X+lO/mQ+R5CCCFE+sicj7Sle/EAWQtCCCGEEPqQ7p4PjUaTnXEIIYQQxkMPE06N+NIuGZvzIYQQQoh3M0GFSRazh6w+PjeT5EMIIYTQMznVNm3Gd8EIIYQQQuRq0vMhhBBC6Jmc7ZI2ST6EEEIIPZN1PtImwy5CCCGEyFHS8yGEEELomUw4TZskH0IIIYSemaCHYRcjPtVWhl2EEEIIkaOk50MIIYTQMxl2SZskH0IIIYSemZD1oQVjHprItcnHvXv3KFq0KBcuXKBChQop1lGpVGzZsoXWrVvnaGz6cuLCLRb8tJ/gaw8Ie6pm9bTeNPMvD0DC60S+WbyDP05c4f4/EdjaWOJfxZdx/VtRsIC9gSPPmEfhUUxc8Bt/nPibV3EJFC3swoKxn1CxVBFDh5YuSa/Txbdep6b//zoBDJi0hp93ntZ5zAfV/dg4t19Oh5puxvbem7NqLzsPXeLm/TCsLPJRpWxRxvVvSQkvN22d2LgExs3bwtZ954lLeE29an5MG9EeV2c7A0aeccs2Hmb+T/sJj1BTxqcQ341oT+XS3oYOK0uMsU0ibXk6sXr8+DFNmjQxdBiZFvMqjtI+hZg2okOyba9i47l0PYThPRtzYPVIVn3bm1sPwgkcvsQAkWZelDqGJn1mY2Zmysa5n3Py56+YPLgNDnZWhg4t3WJexVEmldcpSf0aflzZ9Y32tnRy95wLMBOM7b134sIterarw54fhvLLvP4kvE6k/eCFvHwVp60zds5m9h67wo9TerJt0SDCnj6n+5c/GjDqjNu89xxj5mwhqHcTDq0JooxPIdoN/J4nkS8MHVqmGWOb4M2PY33cjFWu7flID3d3d0OHkCUNapamQc3SKW6zs7Fi8/wBOmXfDW/Phz1m8DA0ksLuTjkRYpbNXb2PQq4OfD/uE22ZVyEXA0aUcWm9TknM85nhlod+QRvbe2/jHN1epvljA/FrMpqL10KoWbEE6uhXrN3+J4sndaXO++8BMG9MIDU7fsPZv+7yfpmihgg7wxauO0DX1jUJbFkDgFmjOrL3+BV+2naSL7o3NHB0mWOMbYI3F6SVi9qmzqA9H3v27KF27do4ODjg7OxM8+bNuX37dop1ExMT6dmzJyVLluTBgwfAm8xy69at2johISF06NABBwcHnJycaNWqFffu3dPZz/LlyyldujQWFhYULFiQAQN0P2RzM3X0K1QqFXY2eafXYPfRv6jgV4TuX/7Ie41G4f/Jd6zaetzQYend8fO3KNl4FNXaT2b4dxuIfP7S0CHpVV5776mjYwFwtMsPwMVrISS8TsS/iq+2jo+3G4XdHTl7+Z4hQsyw+ITXBF8LIaDqv20wMTHBv6ovZy7fNWBkmWeMbUqStMJpVm/GyqDJx8uXLxk6dChnz55l//79mJiY0KZNGzQajU69uLg42rdvT3BwMEePHqVIkeRzBRISEmjUqBG2trYcPXqU48ePY2NjQ+PGjYmPjwdg0aJF9O/fn759+3L58mW2bdtGiRIlcqStWRUbl8CkBdto17BynvkCALj/z1NWbD5G8SIF+HVeP3q0q82omZtYv+OUoUPTmw+ql+L78V3YvGAg4we05MT5W3w8ZCGJiZp3PzgPyGvvPY1Gw5g5m6larhh+xT0ACI9QY57PFHvb/Dp1CzjZEh6hNkSYGRYRFU1iooYCTrY65QWc7PJMG/7LGNsk0segwy7t2rXTub98+XIKFCjA33//jY2NDQDR0dE0a9aMuLg4Dh48iL19yhPeNmzYgEaj4YcfftCOk61YsQIHBwcOHTpEw4YN+frrrxk2bBiDBw/WPq5KlSqpxhcXF0dc3L9jxmq1Yf4YEl4n0mv0chQUpo9Mfd5BbqTRKFTwK8LYfi0BKOfrybXbj1mx+RidmlczcHT60bZhZe3/S5XwoFSJQrzfdiLHz9+k7lu/tPOivPjeC5r+C9duP2bH0sHvrixENjLefousM2jPx82bN+nUqRPFihXDzs4Ob29vAO2wCkCnTp14+fIle/fuTTXxALh48SK3bt3C1tYWGxsbbGxscHJyIjY2ltu3bxMeHs6jR4+oX79+uuObOnUq9vb22punp2em25pZCa8T6fnVckIeR7Jp/oA88cvzbW4udvgW1Z2b8563G/+EPTNQRNnPu5ALzg423Al5YuhQsiQvvveCZvzC3uNX2LJwIB6ujtpyV2c74hMSef4iRqf+k8gXeeZsF2cHG0xNTZJNxHwSqc4zbfgvY2xTkqR1PrJ6M1YGTT5atGhBZGQky5Yt49SpU5w69aYrPmmYBKBp06ZcunSJkydPprmv6OhoKleuTHBwsM7txo0bdO7cGSurjH9wjho1iufPn2tvISEhGd5HViR9+N8JecLmBQNwsrfO0ePrQ7Vyxbh1P0yn7NaD8Fw5aVFfHoU9I/L5S9xccudpqemR1957iqIQNOMXdh2+xOYFA/DycNbZXr6kJ/nMTDly5oa27Nb9MB6GPuP9st45HG3mmOczo0JJTw6fua4t02g0HDlzgypl88aE2f8yxjaJ9DHYsEtERATXr19n2bJl1KlTB4Bjx44lq/f5559TpkwZWrZsyc6dO/H3909xf5UqVWLDhg24urpiZ5dyxuzt7c3+/fupV69eumK0sLDAwsIinS3KuOiYOO4+/PfX8YNHEVy+8RBHu/y4udjT/csfuXQ9hPUzPyVRoxD2/2Ogjnb5Mc+XN05U+rxzPRr3msWsFb/TukElzl+5z+qtJ5j9VUdDh5Zu/32d7r/1OjnYWTP9h920qFceV2c77v3zlAnzf6NoYRc+qF7SgFGnzdjee0HTf2HT3nOsntYbG2tLbbx21pZYWZpjZ2NFYIvqjJu3BUf7/NhaWzJq5q9UKeudZ850AejX+QP6TVxDRb8iVCrtzaL1B3n5Ko7AFtUNHVqmGWObAL2cKiun2mYDR0dHnJ2dWbp0KQULFuTBgwd8+eWXKdYdOHAgiYmJNG/enN27d1O7du1kdQIDA5k+fTqtWrVi0qRJFC5cmPv377N582ZGjhxJ4cKFmTBhAp999hmurq40adKEFy9ecPz4cQYOHJjdzU1R8NUHtOo3T3t/zJwtAHRsVpWg3k3Zc/QyAP5dvtN53G8LB1G7sk/OBZoFlUp5sWZaHyYt3Mb0H/dQxMOZb4a2pX3j1Ofa5DbBVx/Q+q3Xaexbr9P0kR/z961/2LDrFM9fvMK9gD0BVUsy6tNmWJjnM1TI72Rs770Vm9/8cGndb75O+bwxgdq5RZOHtEVloqLHqOXEx7+mXrWSfJdH5rEkaduwMk+jopmyZCfhES8o+14hfp3XP08PURhjm0BWOH0XlaIoiqEO/scffzBo0CDu3LmDr68v8+bNIyAggC1btlChQoVkK5zOmjWLCRMmsGfPHmrWrJlshdPQ0FCCgoLYtWsXL168oFChQtSvX58ZM2Zoe0OWLFnC7NmzuXPnDi4uLnz00UfMmzcvlQh1qdVq7O3tefwkKtXelbzIGJNrjcHe1dnDCF8iNIb76Mk2ZqbG/HVhHNRqNW7O9jx//jxbPseTvieWH7lKfhvbdz8gDTHRL+hZ1y/bYjUkgyYfeY0kH3mHJB+5nyQfwhByKvlYcfSaXpKPHnVKGmXykfsGb4UQQog8TlY4TZuk6UIIIYSR+fbbb1GpVAwZMkRbFhsbS//+/XF2dsbGxoZ27doRFqZ7NuKDBw9o1qwZ+fPnx9XVlREjRvD69Wu9xyfJhxBCCKFnhryw3JkzZ1iyZAnlypXTKf/iiy/Yvn07v/zyC4cPH+bRo0e0bdtWuz0xMZFmzZoRHx/PiRMnWLVqFStXrmTcuHFZei5SIsmHEEIIoWcmerplVHR0NIGBgSxbtgxHx38X2nv+/Dk//vgjs2bN4oMPPqBy5cqsWLGCEydO8OeffwKwd+9e/v77b3766ScqVKhAkyZNmDx5Mt9//73O+lv6IMmHEEIIoWf67PlQq9U6t7cv+/Ff/fv3p1mzZjRo0ECn/Ny5cyQkJOiUlyxZkiJFimgX8Tx58iRly5bFzc1NW6dRo0ao1WquXLmiz6dHkg8hhBAiN/P09NS51MfUqVNTrPfzzz9z/vz5FLeHhoZibm6Og4ODTrmbmxuhoaHaOm8nHknbk7bpk5ztIoQQQuiZPs92CQkJ0TnVNqWVt0NCQhg8eDD79u3D0tIyi0fOftLzIYQQQuiZPi8sZ2dnp3NLKfk4d+4c4eHhVKpUCTMzM8zMzDh8+DDz5s3DzMwMNzc34uPjiYqK0nlcWFgY7u5vLv7p7u6e7OyXpPtJdfRFkg8hhBAij6tfvz6XL1/WubDq+++/T2BgoPb/+fLlY//+/drHXL9+nQcPHlCjRg0AatSoweXLlwkPD9fW2bdvH3Z2dpQqVUqv8cqwixBCCKFnJqgwyeLAS0Yeb2trS5kyZXTKrK2tcXZ21pb36tWLoUOH4uTkhJ2dHQMHDqRGjRpUr/7mIn4NGzakVKlSdOnShWnTphEaGsqYMWPo37+/3i+yKsmHEEIIoWdvD5tkZR/6NHv2bExMTGjXrh1xcXE0atSIhQsXarebmpqyY8cOPv/8c2rUqIG1tTXdunVj0qRJ+g0EubZLhsi1XfIOubZL7ifXdhGGkFPXdtlw8qZeru3ycQ0fubaLEEIIId5N9f//sroPYyXJhxBCCKFnuXHYJTeRPkIhhBBC5Cjp+RBCCCH0TKWHs11k2EUIIYQQ6SbDLmmT5EMIIYTQM0k+0iZzPoQQQgiRo6TnQwghhNAzOdU2bZJ8CFRG2LdnanxNMjpZnYyXG2mMbXU7wMTE+F6nnGCienPL6j6MlQy7CCGEECJHSc+HEEIIoWcy7JI2ST6EEEIIPZOzXdImwy5CCCGEyFHS8yGEEELomYqsD5sYcceHJB9CCCGEvsnZLmmTYRchhBBC5Cjp+RBCCCH0TM52SZskH0IIIYSeydkuaZPkQwghhNAzFVmfMGrEuYfM+RBCCCFEzpKeDyGEEELPTFBhksVxE2O8/lESST6EEEIIPZNhl7TJsIsQQgghcpT0fAghhBD6Jl0faZLkQwghhNAzWecjbTLsIoQQQogcJT0fQgghhL7pYZExI+74kORDCCGE0DeZ8pE2GXYRQgghRI6Sng8DOnHhFgt+2k/wtQeEPVWzelpvmvmX127ffjCYlZuPc/HaA56pYzi0Joiy7xU2YMQZN2vF7+w4eJGb98OwtMhH1XLFmDCgFT7eboYOLcuWbTzM/J/2Ex6hpoxPIb4b0Z7Kpb0NHVam/PjrUZZvOkrI40gAShZzZ0SvJnxYq7SBI8uavPwapfX5kPA6kW8W7+CPE1e4/08EtjaW+FfxZVz/VhQsYG/gyDMuL79OqZKujzRJz4cBxbyKo7RPIaaN6JDK9niqly/G+AGtcjgy/Tlx/ha929dl7/LhbF4wgITXibQduICXr+IMHVqWbN57jjFzthDUuwmH1gRRxqcQ7QZ+z5PIF4YOLVM8XB0YP6AVB1eP5MCqEdR5/z0Chy/l6u3Hhg4t0/L6a5TW58Or2HguXQ9heM/GHFg9klXf9ubWg3AChy8xQKRZk9dfp9So9PTPWEnPhwE1qFmaBjVT/2X5cdOqADx4FJFTIendr/P769xfOP4TfBqOIvhqCLUqlTBQVFm3cN0BurauSWDLGgDMGtWRvcev8NO2k3zRvaGBo8u4JnXL6twf268lyzcd4+xfd/ErXtBAUWVNXn+N0vp8sLOxYvP8ATpl3w1vz4c9ZvAwNJLC7k45EaJe5PXXKTVyVdu05aqej6VLl+Lh4YFGo9Epb9WqFT179uT27du0atUKNzc3bGxsqFKlCn/88YdO3YULF+Lj44OlpSVubm589NFH2m0ajYZp06ZRokQJLCwsKFKkCN98802OtE28oY6OBcDRLr+BI8m8+ITXBF8LIaCqr7bMxMQE/6q+nLl814CR6UdiooZNe88S8yqeKmWLGjqcTDH21ygl6uhXqFQq7GysDB1Kuv0vvk7ijVzV89G+fXsGDhzIwYMHqV+/PgCRkZHs2bOHXbt2ER0dTdOmTfnmm2+wsLBg9erVtGjRguvXr1OkSBHOnj3LoEGDWLNmDTVr1iQyMpKjR49q9z9q1CiWLVvG7NmzqV27No8fP+batWuGau7/HI1Gw6hZv1KtfDFKlfAwdDiZFhEVTWKihgJOtjrlBZzsuHkvzEBRZd2VW//QqOdMYuNfY21lwZrpfShZLG/2ehjra5Sa2LgEJi3YRruGlfNU8mHMr5NM+Uhbrko+HB0dadKkCevWrdMmH7/++isuLi7Uq1cPExMTypf/d0Lm5MmT2bJlC9u2bWPAgAE8ePAAa2trmjdvjq2tLV5eXlSsWBGAFy9eMHfuXBYsWEC3bt0AKF68OLVr1041nri4OOLi/p2boFars6PZ/zOGT9vI1duP2b3sC0OHIlLg4+XGkbWjUEe/4rf9F+g3YQ07lgzOswnI/4qE14n0Gr0cBYXpI1OePyYMQLKPNOWqYReAwMBANm3apP3SX7t2LR07dsTExITo6GiGDx+On58fDg4O2NjYcPXqVR48eADAhx9+iJeXF8WKFaNLly6sXbuWmJgYAK5evUpcXJw2qUmPqVOnYm9vr715enrqv8H/I0ZM28jvR/9i+6JBFHJzNHQ4WeLsYIOpqUmyCXFPItW4OtsZKKqsM89nRjHPAlTwK8L4Aa0o41OIxT8fMnRYmWKsr9F/JbxOpOdXywl5HMmm+QPyVK8H/O+8TiK5XJd8tGjRAkVR2LlzJyEhIRw9epTAwEAAhg8fzpYtW5gyZQpHjx4lODiYsmXLEh8fD4CtrS3nz59n/fr1FCxYkHHjxlG+fHmioqKwssr4H+WoUaN4/vy59hYSEqLXtv4vUBSFEdM2svPQRbYtGoRXIRdDh5Rl5vnMqFDSk8NnrmvLNBoNR87cyLNzJFKiURTi418bOoxM+V94jZISjzshT9i8YABO9taGDinDjPl1krNd0parhl0ALC0tadu2LWvXruXWrVv4+vpSqVIlAI4fP0737t1p06YNANHR0dy7d0/n8WZmZjRo0IAGDRowfvx4HBwcOHDgAE2bNsXKyor9+/fTu3fvdMViYWGBhYWFXtv3tuiYOO4+fKK9/+BRBJdvPMTRLj+F3Z149vwlD8OeEfrkOQC37r8ZA3V1tsMtj/wqGP7dRn79/SzrZvTFJr8lYU/fDF3Z2VhiZWlu4Ogyr1/nD+g3cQ0V/YpQqbQ3i9Yf5OWrOAJbVDd0aJkyccFvNKhZGk93R17ExPLrnrMcO3eTTfP7GTq0TMvrr1Fanw9uLvZ0//JHLl0PYf3MT0nUKIRFvPnbcrTLj3m+XPfRnqq8/jqlRs52SVuufIcGBgbSvHlzrly5wieffKIt9/HxYfPmzbRo0QKVSsXYsWN1zozZsWMHd+7coW7dujg6OrJr1y40Gg2+vr5YWloSFBTEyJEjMTc3p1atWjx58oQrV67Qq1cvQzST4KsPaNVvnvb+mDlbAOjYrCrfj+vC7qOXGTh5rXZ77zErARjZuwlBfZrmaKyZtXzTmwm/zT+bq1P+/bhP6JyHP1zaNqzM06hopizZSXjEC8q+V4hf5/XPs13FT59F8/mE1YQ9VWNnY0npEoXYNL8f9ar5GTq0TMvrr1Fanw9BvZuy5+hlAPy7fKfzuN8WDqJ2ZZ+cCzSL8vrrJDJHpSiKYugg/kuj0VC4cGEeP37M7du3KVasGAD37t2jZ8+e/Pnnn7i4uBAUFMQvv/xChQoVmDNnDseOHWPMmDFcunSJ2NhYfHx8GD16NB06dNDud+rUqSxbtoxHjx5RsGBBPvvsM0aNGpWuuNRqNfb29jx+EoWdnfH8YZiYGHF6LUQO0mhy3cdplhnb54NarcbN2Z7nz59ny+d40vfEsb8eYmObtf1Hv1BTu0zhbIvVkHJl8pFbSfIhhEiLJB+5X44lH1f0lHyUNs7kI9dNOBVCCCGEccuVcz6EEEKIvEwfZ6vI2S5CCCGESDc52yVtknwIIYQQeiYLnKZN5nwIIYQQIkdJz4cQQgihb9L1kSZJPoQQQgg9kwmnaZNhFyGEEELkKEk+hBBCCD1LOtslq7eMmDp1KlWqVMHW1hZXV1dat27N9evXderExsbSv39/nJ2dsbGxoV27doSFhenUefDgAc2aNSN//vy4uroyYsQIXr/W70UmJfkQQggh9Eylp1tGHD58mP79+/Pnn3+yb98+EhISaNiwIS9fvtTW+eKLL9i+fTu//PILhw8f5tGjR7Rt21a7PTExkWbNmhEfH8+JEydYtWoVK1euZNy4cZl7IlIhy6tngCyvLoRIiyyvnvvl1PLqp6890svy6lVLemQ61idPnuDq6srhw4epW7cuz58/p0CBAqxbt46PPvoIgGvXruHn58fJkyepXr06u3fvpnnz5jx69Ag3NzcAFi9eTFBQEE+ePMHcXD9XI5eeDyGEEELf9Nj1oVardW5xcXHpCuH58+cAODk5AXDu3DkSEhJo0KCBtk7JkiUpUqQIJ0+eBODkyZOULVtWm3gANGrUCLVazZUrVzLxRKRMkg8hhBBCz1R6+gfg6emJvb299jZ16tR3Hl+j0TBkyBBq1apFmTJlAAgNDcXc3BwHBwedum5uboSGhmrrvJ14JG1P2qYvcqqtEEIIkYuFhIToDLtYWFi88zH9+/fnr7/+4tixY9kZWqZJ8iGEEELomT6v7WJnZ5ehOR8DBgxgx44dHDlyhMKFC2vL3d3diY+PJyoqSqf3IywsDHd3d22d06dP6+wv6WyYpDr6IMMuQgghhJ4Z4mwXRVEYMGAAW7Zs4cCBAxQtWlRne+XKlcmXLx/79+/Xll2/fp0HDx5Qo0YNAGrUqMHly5cJDw/X1tm3bx92dnaUKlUqgxGlTno+hBBCCH0zwPLq/fv3Z926dfz222/Y2tpq52jY29tjZWWFvb09vXr1YujQoTg5OWFnZ8fAgQOpUaMG1atXB6Bhw4aUKlWKLl26MG3aNEJDQxkzZgz9+/dP13BPeknyIYQQQhiBRYsWARAQEKBTvmLFCrp37w7A7NmzMTExoV27dsTFxdGoUSMWLlyorWtqasqOHTv4/PPPqVGjBtbW1nTr1o1JkybpNVZZ5yMDZJ0PIURaZJ2P3C+n1vk4fzNUL+t8VPJxz7ZYDUl6PoQQQgh908OEUyO+rpwkH5mhj1nMInsZW4eeygjfcMb2GoHx9RIIkV0k+RBCCCH0zADzTfMUST6EEEIIfZPsI02yzocQQgghcpT0fAghhBB69va1WbKyD2MlyYcQQgihZ/pcXt0YybCLEEIIIXKU9HwIIYQQeibzTdMmyYcQQgihb5J9pEmSDyGEEELPZMJp2mTOhxBCCCFylPR8CCGEEHqmQg9nu+glktxJkg8hhBBCz2TKR9pk2EUIIYQQOUp6PoQQQgg9k0XG0ibJhxBCCKF3MvCSFhl2EUIIIUSOkp4PIYQQQs9k2CVtknwIIYQQeiaDLmmTYRchhBBC5Cjp+RBCCCH0TIZd0vY/lXwEBARQoUIF5syZQ0xMDF26dGHfvn28ePGCZ8+e4eDgYOgQeRQexcQFv/HHib95FZdA0cIuLBj7CRVLFTF0aJly/Pwt5q/5g4vXHhD6VM1P0/vQLKC8ocPKkvKtxhPyODJZea+P6jB9ZAcDRKRfs1fuZdL32/isYwBTh31k6HAy5dulu5j2w26dMh8vV079MtZAEenPso2Hmf/TfsIj1JTxKcR3I9pTubS3ocPKEmNsk1zbJW3/U8nH21atWsXRo0c5ceIELi4u2NvbGzokotQxNOkzm9qVfdg493NcHGy4HfIEBzsrQ4eWaTGv4ijzXiE+aVmDLiOXGTocvdi/cjiJiYr2/tU7j2g74Hta1a9owKj04/yV+6zccpzSPoUMHUqWlSxWkC0LBmjvm5nl/VHmzXvPMWbOFmZ9+TGVy3izeP1B2g38njO/jqOAk62hw8sUY2wTIJM+3uF/Nvm4ffs2fn5+lClTxtChaM1dvY9Crg58P+4TbZlXIRcDRpR1H9YqzYe1Shs6DL1ycdT9QJyzeh9FC7tQq1IJA0WkH9ExcfQdt5K5X3VixvI9hg4ny8xMTXBzsTN0GHq1cN0BurauSWDLGgDMGtWRvcev8NO2k3zRvaGBo8scY2yTeLe8/1MgFS9fvqRr167Y2NhQsGBBZs6cqd0WEBDAzJkzOXLkCCqVioCAAMMF+pbdR/+igl8Run/5I+81GoX/J9+xautxQ4cl0hCf8Jpfdp8hsEV1VHl8gHbEtA00rFWGgGolDR2KXtwJeUKppqOp2HoCfceu4mFo8qGyvCQ+4TXB10IIqOqrLTMxMcG/qi9nLt81YGSZZ4xtSqLS081YGW3yMWLECA4fPsxvv/3G3r17OXToEOfPnwdg8+bN9OnThxo1avD48WM2b96c4j7i4uJQq9U6t+x0/5+nrNh8jOJFCvDrvH70aFebUTM3sX7HqWw9rsi8nYcu8Tz6FZ2aVzd0KFmyae9ZLl4LYVz/loYORS8ql/FiwbhP+GVuP2YEfcz9RxE07TuHFy9jDR1apkVERZOYqEk2FFHAyY7wiOz9bMouxtimJEkTTrN6M1ZGOewSHR3Njz/+yE8//UT9+vWBN3M8ChcuDICTkxP58+fH3Nwcd3f3VPczdepUJk6cmCMxA2g0ChX8ijC235svgHK+nly7/ZgVm4/RqXm1HItDpN9P207SoEYpChYw/JyhzHoY+oxRMzexecEALC3yGTocvfiw5r9DfaV9CvF+GS/KtRzP1j8u0KVVDQNGJoQAI+35uH37NvHx8VSr9u8XtpOTE76+vmk8KrlRo0bx/Plz7S0kJETfoepwc7HDt6huMvSetxv/hD3L1uOKzAl5HMnhM9fz/JfZxWsPeBL5goAu3+FSfRAu1Qdx/Pwtlmw4jEv1QSQmagwdYpbZ2+anRBFX7j58YuhQMs3ZwQZTUxOeRL7QKX8SqcbVOW/ObTHGNiVR6emfsTLKng99sbCwwMLCIseOV61cMW7dD9Mpu/UgnMLuTjkWg0i/tdv/pICjLQ3z+ITaulV8Ob7+K52yAZN+wsfbjcFdP8TUNO//RomOiePuP0/p4FLF0KFkmnk+MyqU9OTwmeva09U1Gg1Hztygd/u6Bo4uc4yxTVpytkuajDL5KF68OPny5ePUqVMUKfJmfYxnz55x48YN/P39DRxd6j7vXI/GvWYxa8XvtG5QifNX7rN66wlmf9XR0KFlWnRMHHdD/v21ef9RBJevP8TBPj+eeTip0mg0rNvxJx2bVcXMzNTQ4WSJrbUlpUp46JTltzLHyd46WXleMXbuFhrXKYOnuxOPnz7n26W7MDUxoV3DyoYOLUv6df6AfhPXUNGvCJVKe7No/UFevoojsEXenXNkjG0S72aUyYeNjQ29evVixIgRODs74+rqyujRozExyd2/4CqV8mLNtD5MWriN6T/uoYiHM98MbUv7xnn311rw1fu0+Gye9v7o2W8m93ZqVo2FE7oYKqwsO3T6Og9DnxHYIm8PuRirR+FR9BmzksjnMTg72lC9fDH2Lh+a7DTpvKZtw8o8jYpmypKdhEe8oOx7hfh1Xv88PURhjG0C6fh4F5WiKMq7q+U90dHRfP7552zevBlbW1uGDRvGzp07tSucDhkyhODgYA4dOpTufarVauzt7Ql9GoWdXd7+w3hbXj9FNCXG9raW1yhvMMbXydio1WrcnO15/vx5tnyOJ31P3H0UgW0W9/9Craaoh3O2xWpIRpt8ZAdJPvIOY3tby2uUNxjj62RsJPnIHYxy2EUIIYQwLH2crWK8yawkH0IIIYSeyVVt05a7Z2AKIYQQwuhI8iGEEEKIHCXDLkIIIYSeybBL2iT5EEIIIfRMH8ujG/Py6jLsIoQQQogcJT0fQgghhJ7JsEvaJPkQQggh9EyWV0+bDLsIIYQQIkdJz4cQQgihb9L1kSZJPoQQQgg9k7Nd0ibDLkIIIYTIUdLzIYQQQuiZnO2SNkk+hBBCCD2TKR9pk2EXIYQQQt9Uerplwvfff4+3tzeWlpZUq1aN06dPZ6kp2UGSDyGEEMJIbNiwgaFDhzJ+/HjOnz9P+fLladSoEeHh4YYOTYckH0IIIYSeqfT0L6NmzZpFnz596NGjB6VKlWLx4sXkz5+f5cuXZ0MrM0+SDyGEEELPkiacZvWWEfHx8Zw7d44GDRpoy0xMTGjQoAEnT57UcwuzRiacZoCiKAC8eKE2cCT6pTLCKdVJr5WxkNcobzDG18nYvFC/+fzO7vefWp3174mkffx3XxYWFlhYWCSr//TpUxITE3Fzc9Mpd3Nz49q1a1mOR58k+ciAFy9eAOBTtIiBIxFCCJEVL168wN7eXu/7NTc3x93dHZ+innrZn42NDZ6euvsaP348EyZM0Mv+DUWSjwzw8PAgJCQEW1vbbP2Fo1ar8fT0JCQkBDs7u2w7Tk6SNuUN0qbcz9jaAznbJkVRePHiBR4eHtmyf0tLS+7evUt8fLxe9qcoSrLvm5R6PQBcXFwwNTUlLCxMpzwsLAx3d3e9xKMvknxkgImJCYULF86x49nZ2RnNh0sSaVPeIG3K/YytPZBzbcqOHo+3WVpaYmlpma3HSIm5uTmVK1dm//79tG7dGgCNRsP+/fsZMGBAjseTFkk+hBBCCCMxdOhQunXrxvvvv0/VqlWZM2cOL1++pEePHoYOTYckH0IIIYSR+Pjjj3ny5Anjxo0jNDSUChUqsGfPnmSTUA1Nko9cyMLCgvHjx6c6rpcXSZvyBmlT7mds7QHjbJMhDRgwINcNs/yXSjHG892EEEIIkWvJImNCCCGEyFGSfAghhBAiR0nyIYQQQogcJcmHyHUCAgIYMmSIocN4Zxze3t7MmTMn04/PSbkpFn26d+8eKpWK4ODgVOuoVCq2bt2aYzGJzHn7PRoTE0O7du2ws7NDpVIRFRVl0NiE/snZLkIIo/b48WMcHR0NHYbIgFWrVnH06FFOnDiBi4tLti8KJnKeJB9CCKOW25aVFu92+/Zt/Pz8KFOmjKFDEdlEhl0MKCAggEGDBjFy5EicnJxwd3fXXiyoc+fOfPzxxzr1ExIScHFxYfXq1QaINmUBAQEMHDiQIUOG4OjoiJubG8uWLdOuqGdra0uJEiXYvXu39jF//fUXTZo0wcbGBjc3N7p06cLTp08N2IrUvX79mgEDBmBvb4+Liwtjx45N9WqYP/zwAw4ODuzfvz+Ho0yftNoSFxdHUFAQnp6eWFhYUKJECX788UftY69cuULz5s2xs7PD1taWOnXqcPv27RyJe8+ePdSuXRsHBwecnZ1p3rx5qsdOTEykZ8+elCxZkgcPHgDJh11CQkLo0KEDDg4OODk50apVK+7du6ezn+XLl1O6dGksLCwoWLBgtqyZsHTpUjw8PNBoNDrlrVq1omfPnty+fZtWrVrh5uaGjY0NVapU4Y8//tCpu3DhQnx8fLC0tMTNzY2PPvpIu02j0TBt2jRKlCiBhYUFRYoU4ZtvvtF7OzLj5cuXdO3aFRsbGwoWLMjMmTO12wICApg5cyZHjhxBpVIREBBguEBFtpHkw8BWrVqFtbU1p06dYtq0aUyaNIl9+/YRGBjI9u3biY6O1tb9/fffiYmJoU2bNgaMOLlVq1bh4uLC6dOnGThwIJ9//jnt27enZs2anD9/noYNG9KlSxdiYmKIiorigw8+oGLFipw9e5Y9e/YQFhZGhw4dDN2MFK1atQozMzNOnz7N3LlzmTVrFj/88EOyetOmTePLL79k79691K9f3wCRvltabenatSvr169n3rx5XL16lSVLlmBjYwPAP//8Q926dbGwsODAgQOcO3eOnj178vr16xyJ++XLlwwdOpSzZ8+yf/9+TExMaNOmTbIv7bi4ONq3b09wcDBHjx6lSJHkV59OSEigUaNG2NracvToUY4fP46NjQ2NGzfWXghs0aJF9O/fn759+3L58mW2bdtGiRIl9N6u9u3bExERwcGDB7VlkZGR7Nmzh8DAQKKjo2natCn79+/nwoULNG7cmBYtWmiTqrNnzzJo0CAmTZrE9evX2bNnD3Xr1tXua9SoUXz77beMHTuWv//+m3Xr1uWaVS5HjBjB4cOH+e2339i7dy+HDh3i/PnzAGzevJk+ffpQo0YNHj9+zObNmw0crcgWijAYf39/pXbt2jplVapUUYKCgpSEhATFxcVFWb16tXZbp06dlI8//jinw0zTf9vw+vVrxdraWunSpYu27PHjxwqgnDx5Upk8ebLSsGFDnX2EhIQogHL9+nXtPgcPHpwj8afF399f8fPzUzQajbYsKChI8fPzUxRFUby8vJTZs2crI0eOVAoWLKj89ddfyR6fG9qhKGm35fr16wqg7Nu3L8XHjho1SilatKgSHx+fU+Gm6cmTJwqgXL58Wbl7964CKEePHlXq16+v1K5dW4mKitKpDyhbtmxRFEVR1qxZo/j6+uo8D3FxcYqVlZXy+++/K4qiKB4eHsro0aNzpC2tWrVSevbsqb2/ZMkSxcPDQ0lMTEyxfunSpZX58+criqIomzZtUuzs7BS1Wp2snlqtViwsLJRly5ZlT+BZ8OLFC8Xc3FzZuHGjtiwiIkKxsrLS/r0MHjxY8ff3N0yAIkdIz4eBlStXTud+wYIFCQ8Px8zMjA4dOrB27Vrgza+/3377jcDAQEOEmaa322BqaoqzszNly5bVliX92goPD+fixYscPHgQGxsb7a1kyZIAOdaNnxHVq1fXuZx1jRo1uHnzJomJiQDMnDmTZcuWcezYMUqXLm2oMNMltbZcuHABU1NT/P39U3xccHAwderUIV++fDkVqo6bN2/SqVMnihUrhp2dHd7e3gDaHgCATp068fLlS/bu3Zvm5MSLFy9y69YtbG1tte8/JycnYmNjuX37NuHh4Tx69CjHeq8CAwPZtGkTcXFxAKxdu5aOHTtiYmJCdHQ0w4cPx8/PDwcHB2xsbLh69aq23R9++CFeXl4UK1aMLl26sHbtWmJiYgC4evUqcXFxubIX7vbt28THx1OtWjVtmZOTE76+vgaMSuQ0ST4M7L8f6CqVStudHBgYyP79+wkPD2fr1q1YWVnRuHFjQ4SZppTa8HZZ0heeRqMhOjqaFi1aEBwcrHO7efOmTpdxXlGnTh0SExPZuHGjoUPJtHdd+tvKyiqHIklZixYtiIyMZNmyZZw6dYpTp04BaIdJAJo2bcqlS5c4efJkmvuKjo6mcuXKyd5/N27coHPnzjne1hYtWqAoCjt37iQkJISjR49qf2AMHz6cLVu2MGXKFI4ePUpwcDBly5bVttvW1pbz58+zfv16ChYsyLhx4yhfvjxRUVEGf82EeBdJPnKxmjVr4unpyYYNG1i7di3t27c32K9PfalUqRJXrlzB29ubEiVK6Nysra0NHV4ySV90Sf788098fHwwNTUFoGrVquzevZspU6YwY8YMQ4SYbqm1pXz58mg0Gg4fPpzi48qVK8fRo0dJSEjIiTB1REREcP36dcaMGUP9+vXx8/Pj2bNnyep9/vnnfPvtt7Rs2TLVdsCb99/NmzdxdXVN9v6zt7fH1tYWb2/vHJs0bGlpSdu2bVm7di3r16/H19eXSpUqAXD8+HG6d+9OmzZtKFu2LO7u7skmxpqZmdGgQQOmTZvGpUuXuHfvHgcOHMDHxwcrK6tcOfm5ePHi5MuXT+f9+OzZM27cuGHAqEROk+Qjl+vcuTOLFy/WTkLN6/r3709kZCSdOnXizJkz3L59m99//50ePXpohzJykwcPHjB06FCuX7/O+vXrmT9/PoMHD9apU7NmTXbt2sXEiRPTXHTM0FJri7e3N926daNnz55s3bqVu3fvcujQIW1vzoABA1Cr1XTs2JGzZ89y8+ZN1qxZw/Xr17M9ZkdHR5ydnVm6dCm3bt3iwIEDDB06NMW6AwcO5Ouvv6Z58+YcO3YsxTqBgYG4uLjQqlUrjh49qm3roEGDePjwIQATJkxg5syZzJs3j5s3b3L+/Hnmz5+fbW0MDAxk586dLF++XOdv3MfHh82bNxMcHMzFixfp3LmzziTbHTt2MG/ePIKDg7l//z6rV69Go9Hg6+uLpaUlQUFBjBw5ktWrV3P79m3+/PNPnTOYDMXGxoZevXoxYsQIDhw4wF9//UX37t0xMZGvo/8lss5HLhcYGMg333yDl5cXtWrVMnQ4Webh4cHx48cJCgqiYcOGxMXF4eXlRePGjXPlh0/Xrl159eoVVatWxdTUlMGDB9O3b99k9WrXrs3OnTtp2rQppqamDBw40ADRpi2ttixatIivvvqKfv36ERERQZEiRfjqq68AcHZ25sCBA4wYMQJ/f39MTU2pUKFCjrwfTUxM+Pnnnxk0aBBlypTB19eXefPmpXr65ZAhQ9BoNDRt2pQ9e/ZQs2ZNne358+fnyJEjBAUF0bZtW168eEGhQoWoX78+dnZ2AHTr1o3Y2Fhmz57N8OHDcXFx0TmFVd8++OADnJycuH79Op07d9aWz5o1i549e1KzZk1cXFwICgpCrVZrtzs4OLB582YmTJhAbGwsPj4+rF+/Xjv3aOzYsZiZmTFu3DgePXpEwYIF+eyzz7KtHRkxffp07RCsra0tw4YN4/nz54YOS+QglaKksmiBEEIIIUQ2yH0/NYUQQghh1CT5EEIIIUSOkuRDCCGEEDlKkg8hhBBC5ChJPoQQQgiRoyT5EEIIIUSOkuRDCCGEEDlKkg8h8pju3bvTunVr7f2AgACGDBmS43EcOnQIlUpFVFRUqnVUKhVbt25N9z4nTJhAhQoVshTXvXv3UKlUBAcHZ2k/QojsI8mHEHrQvXt3VCoVKpUKc3NzSpQowaRJk3j9+nW2H3vz5s1Mnjw5XXXTkzAIIUR2k+XVhdCTxo0bs2LFCuLi4ti1axf9+/cnX758jBo1Klnd+Ph4zM3N9XJcJycnvexHCCFyivR8CKEnFhYWuLu74+Xlxeeff06DBg3Ytm0b8O9QyTfffIOHhwe+vr4AhISE0KFDBxwcHHBycqJVq1Y6Vy5NTExk6NChODg44OzszMiRI/nvFRH+O+wSFxdHUFAQnp6eWFhYUKJECX788Ufu3btHvXr1gDcXbFOpVHTv3h0AjUbD1KlTKVq0KFZWVpQvX55ff/1V5zi7du3ivffew8rKinr16iW7wmp6BAUF8d5775E/f36KFSvG2LFjU7xa7pIlS/D09CR//vx06NAh2XU/fvjhB/z8/LC0tKRkyZIsXLgww7EIIQxHkg8hsomVlRXx8fHa+/v37+f69evs27ePHTt2kJCQQKNGjbC1teXo0aMcP34cGxsbGjdurH3czJkzWblyJcuXL+fYsWNERkayZcuWNI/btWtX1q9fz7x587h69SpLlizBxsYGT09PNm3aBMD169d5/Pgxc+fOBWDq1KmsXr2axYsXc+XKFb744gs++eQT7eXpQ0JCaNu2LS1atCA4OJjevXvz5ZdfZvg5sbW1ZeXKlfz999/MnTuXZcuWMXv2bJ06t27dYuPGjWzfvp09e/Zw4cIF+vXrp92+du1axo0bxzfffMPVq1eZMmUKY8eOZdWqVRmORwhhIIoQIsu6deumtGrVSlEURdFoNMq+ffsUCwsLZfjw4drtbm5uSlxcnPYxa9asUXx9fRWNRqMti4uLU6ysrJTff/9dURRFKViwoDJt2jTt9oSEBKVw4cLaYymKovj7+yuDBw9WFEVRrl+/rgDKvn37Uozz4MGDCqA8e/ZMWxYbG6vkz59fOXHihE7dXr16KZ06dVIURVFGjRqllCpVSmd7UFBQsn39F6Bs2bIl1e3Tp09XKleurL0/fvx4xdTUVHn48KG2bPfu3YqJiYny+PFjRVEUpXjx4sq6det09jN58mSlRo0aiqIoyt27dxVAuXDhQqrHFUIYlsz5EEJPduzYgY2NDQkJCWg0Gjp37syECRO028uWLaszz+PixYvcunULW1tbnf3ExsZy+/Ztnj9/zuPHj6lWrZp2m5mZGe+//36yoZckwcHBmJqa4u/vn+64b926RUxMDB9++KFOeXx8PBUrVgTg6tWrOnEA1KhRI93HSLJhwwbmzZvH7du3iY6O5vXr19pL2ScpUqQIhQoV0jmORqPh+vXr2Nracvv2bXr16kWfPn20dV6/fo29vX2G4xFCGIYkH0LoSb169Vi0aBHm5uZ4eHhgZqb752Vtba1zPzo6msqVK7N27dpk+ypQoECmYrCyssrwY6KjowHYuXOnzpc+vJnHoi8nT54kMDCQiRMn0qhRI+zt7fn555+ZOXNmhmNdtmxZsmTI1NRUb7EKIbKXJB9C6Im1tTUlSpRId/1KlSqxYcMGXF1dk/36T1KwYEFOnTpF3bp1gTe/8M+dO0elSpVSrF+2bFk0Gg2HDx+mQYMGybYn9bwkJiZqy0qVKoWFhQUPHjxItcfEz89PO3k2yZ9//vnuRr7lxIkTeHl5MXr0aG3Z/fv3k9V78OABjx49wsPDQ3scExMTfH19cXNzw8PDgzt37hAYGJih4wshcg+ZcCqEgQQGBuLi4kKrVq04evQod+/e5dChQwwaNIiHDx8CMHjwYL799lu2bt3KtWvX6NevX5prdHh7e9OtWzd69uzJ1q1btfvcuHEjAF5eXqhUKnbs2MGTJ0+Ijo7G1taW4cOH88UXX7Bq1Spu377N+fPnmT9/vnYS52effcbNmzcZMWIE169fZ926daxcuTJD7fXx8eHBgwf8/PPP3L59m3nz5qU4edbS0pJu3bpx8eJFjh49yqBBg+jQoQPu7u4ATJw4kalTpzJv3jxu3LjB5cuXWbFiBbNmzcpQPEIIw5HkQwgDyZ8/P0eOHKFIkSK0bdsWPz8/evXqRWxsrLYnZNiwYXTp0oVu3bpR4//at0OUxYM4jsPfPYDZYBIMGvS1vskmYhAUj6BF/sVmMYigR9Ag6AUEi1fwRubdsLCwLLuwYYcNz5OHYaZ9GH7z+ZlarZbpdPrHfU+nU+bzeVarVdrtdpbLZd7vd5Kk0Whkt9tls9mkXq+nqqokyX6/z3a7zfF4TKfTyWg0yvP5TLPZTPJ9DuN+v+fxeOTj4yPn8zmHw+Gv7juZTLJer1NVVfr9fl6vV7bb7S/rWq1WZrNZxuNxhsNher3eT19pF4tFLpdLrtdrut1uBoNBbrfbj7MC/78vX383uQYA8A94+QAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARX0DRZ7Z9hoD+w4AAAAASUVORK5CYII=\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# 12. Output the model\nexample_input = torch.randn(1, 3, 75, 100)\nscripted_model = torch.jit.trace(model, example_input)\nscripted_model.save(\"skin_cancer_model.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:12:34.654011Z","iopub.execute_input":"2025-07-31T23:12:34.655131Z","iopub.status.idle":"2025-07-31T23:12:35.020168Z","shell.execute_reply.started":"2025-07-31T23:12:34.655093Z","shell.execute_reply":"2025-07-31T23:12:35.019137Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# 13. Evaluate the model \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncnn_model = torch.jit.load(\"/kaggle/working/skin_cancer_model.pt\", map_location=device)\ncnn_model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:12:38.197294Z","iopub.execute_input":"2025-07-31T23:12:38.197657Z","iopub.status.idle":"2025-07-31T23:12:38.235981Z","shell.execute_reply.started":"2025-07-31T23:12:38.197603Z","shell.execute_reply":"2025-07-31T23:12:38.234676Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"RecursiveScriptModule(\n  original_name=SkinCNN\n  (features): RecursiveScriptModule(\n    original_name=Sequential\n    (0): RecursiveScriptModule(original_name=Conv2d)\n    (1): RecursiveScriptModule(original_name=ReLU)\n    (2): RecursiveScriptModule(original_name=Conv2d)\n    (3): RecursiveScriptModule(original_name=ReLU)\n    (4): RecursiveScriptModule(original_name=MaxPool2d)\n    (5): RecursiveScriptModule(original_name=Dropout)\n    (6): RecursiveScriptModule(original_name=Conv2d)\n    (7): RecursiveScriptModule(original_name=ReLU)\n    (8): RecursiveScriptModule(original_name=Conv2d)\n    (9): RecursiveScriptModule(original_name=ReLU)\n    (10): RecursiveScriptModule(original_name=MaxPool2d)\n    (11): RecursiveScriptModule(original_name=Dropout)\n  )\n  (classifier): RecursiveScriptModule(\n    original_name=Sequential\n    (0): RecursiveScriptModule(original_name=Flatten)\n    (1): RecursiveScriptModule(original_name=Linear)\n    (2): RecursiveScriptModule(original_name=ReLU)\n    (3): RecursiveScriptModule(original_name=Dropout)\n    (4): RecursiveScriptModule(original_name=Linear)\n  )\n)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 14. Ouptut the model weight as well\ntorch.save(model.state_dict(), \"skin_cancer_model_weights.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:12:47.093049Z","iopub.execute_input":"2025-07-31T23:12:47.093799Z","iopub.status.idle":"2025-07-31T23:12:47.152383Z","shell.execute_reply.started":"2025-07-31T23:12:47.093749Z","shell.execute_reply":"2025-07-31T23:12:47.151228Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# 15. Checking accuracy (This can be improved but for the purpose of the Hackathon I will leave the accuracy as is to continue with integrating this with an edge device)\nfrom sklearn.metrics import classification_report\nclass_names = ['Melanocytic nevi', 'Melanoma', 'Benign keratosis', 'Basal cell carcinoma',\n               'Actinic keratoses', 'Vascular lesions', 'Dermatofibroma']\nprint(classification_report(all_labels, all_preds, target_names=class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:12:48.939293Z","iopub.execute_input":"2025-07-31T23:12:48.939675Z","iopub.status.idle":"2025-07-31T23:12:48.964524Z","shell.execute_reply.started":"2025-07-31T23:12:48.939646Z","shell.execute_reply":"2025-07-31T23:12:48.963543Z"}},"outputs":[{"name":"stdout","text":"                      precision    recall  f1-score   support\n\n    Melanocytic nevi       0.84      0.91      0.88      1341\n            Melanoma       0.52      0.42      0.47       223\n    Benign keratosis       0.49      0.44      0.46       220\nBasal cell carcinoma       0.54      0.50      0.52       103\n   Actinic keratoses       0.41      0.31      0.35        65\n    Vascular lesions       0.67      0.43      0.52        28\n      Dermatofibroma       0.00      0.00      0.00        23\n\n            accuracy                           0.75      2003\n           macro avg       0.50      0.43      0.46      2003\n        weighted avg       0.72      0.75      0.73      2003\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"#16. This information is useful for debugging and continueing the steps further below\nstate_dict = torch.load(\"/kaggle/working/skin_cancer_model_weights.pth\", map_location=device)\nfor k in state_dict.keys():\n    print(k)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T23:12:51.814860Z","iopub.execute_input":"2025-07-31T23:12:51.815177Z","iopub.status.idle":"2025-07-31T23:12:51.831723Z","shell.execute_reply.started":"2025-07-31T23:12:51.815156Z","shell.execute_reply":"2025-07-31T23:12:51.830335Z"}},"outputs":[{"name":"stdout","text":"features.0.weight\nfeatures.0.bias\nfeatures.2.weight\nfeatures.2.bias\nfeatures.6.weight\nfeatures.6.bias\nfeatures.8.weight\nfeatures.8.bias\nclassifier.1.weight\nclassifier.1.bias\nclassifier.4.weight\nclassifier.4.bias\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Outputting model to PyTorch PT format and also TFLite for Mobile and Laptop integration with LLM**","metadata":{}},{"cell_type":"markdown","source":"This is on my laptop when I ran the script below manually via command prompt on a Windows 11 (this was painful to copy and modify but I hope you appreciate this):\n>\n> pip list\n>\n> Package                  Version\n------------------------ -----------\n> \n> absl-py                  2.3.1\n> \n> aiohappyeyeballs         2.6.1\n> \n> aiohttp                  3.12.15\n> \n> aiosignal                1.4.0\n> \n> annotated-types          0.7.0\n> \n> anyio                    4.9.0\n> \n> astunparse               1.6.3\n> \n> attrs                    25.3.0\n> \n> certifi                  2025.7.14\n> \n> charset-normalizer       3.4.2\n> \n> click                    8.2.1\n> \n> colorama                 0.4.6\n> \n> coloredlogs              15.0.1\n> \n> dataclasses-json         0.6.7\n> \n> fastapi                  0.116.1\n> \n> filelock                 3.18.0\n> \n> flatbuffers              25.2.10\n> \n> frozenlist               1.7.0\n> \n> fsspec                   2025.7.0\n> \n> gast                     0.6.0\n> \n> google-pasta             0.2.0\n> \n> greenlet                 3.2.3\n> \n> grpcio                   1.74.0\n> \n> h11                      0.16.0\n> \n> h5py                     3.14.0\n> \n> httpcore                 1.0.9\n> \n> httpx                    0.28.1\n> \n> httpx-sse                0.4.1\n> \n> humanfriendly            10.0\n> \n> idna                     3.10\n> \n> intel-cmplr-lic-rt       2025.2.0\n> \n> intel-opencl-rt          2025.2.0\n> \n> Jinja2                   3.1.6\n> \n> joblib                   1.5.1\n> \n> jsonpatch                1.33\n> \n> jsonpointer              3.0.0\n> \n> keras                    3.11.1\n> \n> langchain                0.3.27\n> \n> langchain-community      0.3.27\n> \n> langchain-core           0.3.72\n> \n> langchain-text-splitters 0.3.9\n> \n> langsmith                0.4.8\n> \n> libclang                 18.1.1\n> \n> Markdown                 3.8.2\n> \n> markdown-it-py           3.0.0\n> \n> MarkupSafe               3.0.2\n> \n> marshmallow              3.26.1\n> \n> mdurl                    0.1.2\n> \n> ml_dtypes                0.5.3\n> \n> mpmath                   1.3.0\n> \n> multidict                6.6.3\n> \n> mypy_extensions          1.1.0\n> \n> namex                    0.1.0\n> \n> networkx                 3.5\n> \n> numpy                    2.3.2\n> \n> ollama                   0.5.1\n> \n> onnx                     1.18.0\n> \n> onnx-tf                  1.6.0\n> \n> onnxruntime              1.22.1\n> \n> opt_einsum               3.4.0\n> \n> optree                   0.17.0\n> \n> orjson                   3.11.1\n> \n> packaging                25.0\n> \n> pandas                   2.3.1\n> \n> pillow                   11.3.0\n> \n> pip                      25.1.1\n> \n> propcache                0.3.2\n> \n> protobuf                 6.31.1\n> \n> pydantic                 2.11.7\n> \n> pydantic_core            2.33.2\n>\n> pydantic-settings        2.10.1\n> \n> Pygments                 2.19.2\n> \n> pyreadline3              3.5.4\n> \n> python-dateutil          2.9.0.post0\n> \n> python-dotenv            1.1.1\n> \n> pytz                     2025.2\n> \n> PyYAML                   6.0.2\n> \n> requests                 2.32.4\n> \n> requests-toolbelt        1.0.0\n> \n> rich                     14.1.0\n> \n> scikit-learn             1.7.1\n> \n> scipy                    1.16.1\n> \n> setuptools               80.9.0\n> \n> six                      1.17.0\n> \n> sniffio                  1.3.1\n>\n> SQLAlchemy               2.0.42\n> \n> starlette                0.47.2\n> \n> sympy                    1.14.0\n> \n> tbb                      2022.2.0\n> \n> tcmlib                   1.4.0\n> \n> tenacity                 9.1.2\n> \n> tensorboard              2.20.0\n> \n> tensorboard-data-server  0.7.2\n> \n> tensorflow               2.20.0rc0\n> \n> termcolor                3.1.0\n> \n> threadpoolctl            3.6.0\n> \n> torch                    2.7.1\n> \n> torchvision              0.22.1\n> \n> typing_extensions        4.14.1\n> \n> typing-inspect           0.9.0\n> \n> typing-inspection        0.4.1\n> \n> tzdata                   2025.2\n> \n> urllib3                  2.5.0\n> \n> uvicorn                  0.35.0\n> \n> Werkzeug                 3.1.3\n> \n> wheel                    0.45.1\n> \n> wrapt                    1.17.2\n> \n> yarl                     1.20.1\n> \n> zstandard                0.23.0 \n","metadata":{}},{"cell_type":"code","source":"!pip install onnx onnx-tf onnxruntime keras","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# You may have to restart the cluster, but keep the .pt file available to run below\n# You could also put all of these pip install to the top of the notebook and then run below later.\n# I put these here so that you know what packages are needed to convert the Pytorch .pt model to onnx and tflite to integrate with AI Edge Gallery or Python/Ollama","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#17. Output this in the format for edge devices (Laptop/Ollama/Gemma3 for phase 1 and Android in phase 2)\n# I made this run locally on my laptop but it also works on Kaggle. To make this work on your laptop, just download the .pt file into a folder and change the paths.\n\nimport torch\nimport onnx\nimport onnxruntime as ort\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\nimport numpy as np\n\n# --- Part 1: Export the PyTorch JIT model to ONNX ---\n\n# Load the JIT-compiled model. Note: The path below is a placeholder and should be updated.\ndevice = torch.device(\"cpu\")\ntry:\n    cnn_model = torch.jit.load(\"/kaggle/input/models/pytorch/default/1/skin_cancer_model.pt\", map_location=device)\n    cnn_model.eval()\nexcept FileNotFoundError:\n    print(\"Error: PyTorch model not found. Please verify the path.\")\n    # Exit or handle the error gracefully\n    cnn_model = None\n\nif cnn_model:\n    # Create the dummy input tensor with the correct size.\n    # The shape should match the expected input of your PyTorch model.\n    dummy_input = torch.randn(1, 3, 75, 100, requires_grad=True)\n\n    # Export the JIT model to ONNX format.\n    onnx_model_path = \"/kaggle/working/skin_cancer_model.onnx\"\n    torch.onnx.export(cnn_model,\n                      dummy_input,\n                      onnx_model_path,\n                      opset_version=11,\n                      input_names=['input'],\n                      output_names=['output'],\n                      dynamic_axes={'input' : {0 : 'batch_size'}})\n\n    print(\"Step 1: JIT model has been successfully exported to ONNX.\")\n\n    # --- Part 2: Convert ONNX to a Keras model and then to TFLite ---\n\n    # Use ONNX Runtime to get the model's output\n    sess = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])\n    output_name = sess.get_outputs()[0].name\n    input_name = sess.get_inputs()[0].name\n    \n    # Create a helper function to run ONNX inference, which will be called by tf.py_function\n    def _run_onnx_inference(input_data):\n        \"\"\"Helper function to run the ONNX session with a numpy array.\"\"\"\n        # Ensure the input is a contiguous numpy array, which is often required\n        # by ONNX Runtime and can resolve data format issues from tf.py_function.\n        outputs = sess.run([output_name], {input_name: np.ascontiguousarray(input_data)})\n        return outputs[0]\n\n    # Create a simple Keras model that wraps the ONNX Runtime session.\n    class ONNXModelWrapper(keras.Model):\n        def __init__(self, onnx_session, output_name, input_name):\n            super(ONNXModelWrapper, self).__init__()\n            self.output_name = output_name\n            self.input_name = input_name\n\n        @tf.function(input_signature=[\n            tf.TensorSpec(shape=(None, 3, 75, 100), dtype=tf.float32)\n        ])\n        def call(self, inputs):\n            # Use tf.py_function to wrap the ONNX inference call.\n            # We must specify the output shape and dtype to ensure the graph\n            # is correctly traced.\n            return tf.py_function(\n                _run_onnx_inference,\n                inp=[inputs],\n                Tout=tf.float32,\n                # Explicitly set the output shape to allow for proper graph building.\n                # The shape can be inferred from the model's output. For this example,\n                # we'll assume a known output shape after the first dimension.\n                # You might need to adjust this based on your model's output.\n                # Example: tf.TensorShape([None, 1000]) for a 1000-class classifier\n                # We will return a placeholder for the output shape here\n                # since it's difficult to determine without knowing the model.\n                # In practice, you would calculate this from the ONNX model's output.\n                name=\"onnx_inference_op\"\n            )\n\n    # Instantiate the wrapper model.\n    onnx_model_wrapper = ONNXModelWrapper(sess, output_name, input_name)\n    onnx_model_wrapper.build(input_shape=(None, 3, 75, 100))\n    \n    # Call the model once with dummy data to build the graph before exporting.\n    dummy_input_tf = tf.convert_to_tensor(dummy_input.detach().numpy())\n    _ = onnx_model_wrapper(dummy_input_tf)\n\n    # Save the wrapper as a TensorFlow SavedModel.\n    tf_saved_model_path = \"tf_saved_model_final\"\n    onnx_model_wrapper.export(tf_saved_model_path)\n\n    print(\"Step 2: ONNX model successfully wrapped in a Keras model and saved.\")\n\n    # --- Part 3: Convert the SavedModel to TFLite, allowing custom ops ---\n\n    tflite_model_path = \"/kaggle/working/skin_cancer_model.tflite\"\n\n    # Convert the SavedModel to a TFLite model using the native converter.\n    # The key change here is to set `allow_custom_ops=True`.\n    # This instructs the converter to keep `tf.py_function` as a custom operation\n    # instead of trying to convert it to a native TFLite op, which caused the error.\n    converter = tf.lite.TFLiteConverter.from_saved_model(tf_saved_model_path)\n    converter.allow_custom_ops = True\n    tflite_model = converter.convert()\n\n    # Save the TFLite model to a file.\n    with open(tflite_model_path, \"wb\") as f:\n        f.write(tflite_model)\n\n    print(\"Step 3: SavedModel successfully converted to TFLite format.\")\n    print(f\"Final TFLite file saved at: {tflite_model_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Understanding the output and interpreting the data**","metadata":{}},{"cell_type":"markdown","source":"**Here is ChatGPT's response to my epoch and data: (hey, why not ask AI to evaluate my model eh?)**","metadata":{}},{"cell_type":"markdown","source":"ðŸ” Understanding the Output Format\nTrain Loss: How well the model fits the training data (lower = better).\n\nTrain Acc: Accuracy on the training data.\n\nVal Loss: How well the model generalizes to unseen data.\n\nVal Acc: Accuracy on validation (test-like) data.\n\nðŸ“ˆ What the model is learning\nHere's what we can infer:\n\nâœ… Improvement in Accuracy\nTraining Accuracy increases steadily:\n\nFrom 66.6% at epoch 1 â†’ ~78.6% at epoch 27.\n\nValidation Accuracy also improves:\n\nFrom 68.7% â†’ ~77.4%\n\nThis means my model is learning and generalizing reasonably well.\n\nðŸ“‰ Loss Trends\nTraining Loss drops from 0.9777 â†’ 0.5708\n\nValidation Loss drops from 0.9429 â†’ fluctuates around 0.65-0.67\n\nThis suggests a decent reduction in error, though validation loss fluctuates, which is common.\n\nðŸ§  Interpretation\nMetric\tTrend\tMeaning\nTrain Loss\tDecreasing steadily\tThe model is fitting the training data better.\nVal Loss\tDecreasing but with fluctuations\tGeneralization is improving, but model might be approaching a plateau.\nTrain Accuracy\tIncreases to ~78.6%\tThe model is learning more patterns from training data.\nVal Accuracy\tImproves to ~77.4%\tModel generalizes fairly well, but may need tuning for further boost.\n\nðŸ”” Warnings / Notes\nFluctuating Validation Loss: Around epoch 16â€“27, the validation loss doesn't improve much â€” it goes up and down. This could mean:\n\nI'm close to model capacity (may not improve much more).\n\nOr slight overfitting might begin if it continues rising.\n\nValidation Accuracy > Training Accuracy (e.g., Epoch 23â€“25): Thatâ€™s usually okay in some cases (like regularization or dropout), but unusual long-term. Will keep an eye on it.\n\nâœ… Is this a good result?\nYes, for a baseline CNN, 77â€“78% validation accuracy is a solid starting point for many real-world problems, especially in medical image classification. Whether it's good enough depends on:\n\nDataset difficulty\n\nLabel quality\n\nRequired clinical/industrial accuracy\n\nðŸ§ª Suggestions for Improvement\nTry deeper models or pretrained backbones (e.g., ResNet18/50).\n\nData augmentation might help generalization.\n\nEarly stopping or learning rate scheduling could improve convergence.\n\nIf available, try more data or class balancing.\n\nðŸ“Œ Summary\nThe model is learning effectively.\n\nIt improves both training and validation accuracy.\n\nTraining loss drops nicely.\n\nValidation accuracy hits ~77.4%, which shows good generalization.\n\nValidation loss fluctuates slightly, suggesting it's time to consider tuning or model improvements.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Here is Gemma's response:**","metadata":{}},{"cell_type":"markdown","source":"\nI've analyzed the model's performance based on the training logs and test results you provided. Here are my findings, presented in a similar format to your example.\n\nðŸ” Understanding the Output Format\nTrain Loss/Acc: Measures how well the model fits the training data.\n\nVal Loss/Acc: Measures how well the model generalizes to new, unseen data from the validation set.\n\nTest Loss/Acc: The final evaluation of the model's performance on a completely separate test set.\n\nðŸ“ˆ What the Model Is Learning\nHere's what we can infer from the metrics:\n\nâœ… Improvement in Accuracy\nTraining Accuracy increases steadily, starting at 66.6% in epoch 1 and reaching ~80.6% by epoch 34.\n\nValidation Accuracy also improves, starting at 66.9% and reaching a high of ~77.5% by epoch 29.\n\nTest Accuracy is 74.9%.\n\nThis shows that the model is learning effectively and generalizing well to new data, although there's a small drop-off in performance from validation to test.\n\nðŸ“‰ Loss Trends\nTraining Loss drops consistently from 1.0166 to 0.5099, indicating the model is getting better at fitting the training data.\n\nValidation Loss drops from 0.8530 to ~0.63, but fluctuates noticeably after epoch 21. This suggests the model may be approaching its optimal performance on the validation set, and further training might not lead to significant improvements.\n\nðŸ§  Interpretation of Metric Trends\nMetric\tTrend\tMeaning\nTrain Loss\tDecreasing steadily\tThe model is successfully learning patterns from the training data.\nVal Loss\tDecreasing, but with fluctuations\tThe model is generalizing better, but may be starting to overfit slightly or has reached a plateau.\nTrain Accuracy\tIncreases to ~80.6%\tThe model is becoming more accurate on the data it has seen.\nVal Accuracy\tIncreases to ~77.5%\tThe model generalizes fairly well, but the fluctuations suggest it may be time to tune hyperparameters or try other improvements.\n\nExport to Sheets\nðŸ”” Warnings / Notes\nFluctuating Validation Loss: After epoch 21, the validation loss doesn't show a clear downward trend and bounces around. This is a classic sign that the model may be close to its optimal capacity or starting to overfit.\n\nImbalanced Classes: The classification report reveals a significant class imbalance. The model performs very well on Melanocytic nevi (with a high F1-score of 0.88), which makes up the majority of the data. However, its performance on other, smaller classes like Vascular lesions and Dermatofibroma is poor (with F1-scores of 0.52 and 0.00, respectively).\n\nZero Performance on Dermatofibroma: The model completely failed to predict any instances of the Dermatofibroma class (precision and recall are 0.00), likely due to the extremely small sample size (23 instances).\n\nâœ… Is This a Good Result?\nThe overall test accuracy of 74.9% is a decent baseline, especially for a multi-class medical image problem. However, the model's poor performance on minority classes is a major concern. For a medical application, a high-performing model is needed across all classes, particularly for rare but potentially critical diagnoses like melanoma.\n\nðŸ§ª Suggestions for Improvement\nAddress Class Imbalance: Implement techniques like class weighting, oversampling the minority classes, or undersampling the majority class.\n\nUse a More Robust Model: Consider using deeper architectures or pretrained models like ResNet, VGG, or EfficientNet, which are more powerful for image classification.\n\nRegularization and Hyperparameter Tuning: Experiment with Early Stopping to prevent overfitting, or adjust the learning rate scheduler to improve convergence.\n\nData Augmentation: Apply more aggressive data augmentation to the training set to help the model generalize better and reduce overfitting.\n\nðŸ“Œ Summary\nYour model shows promising signs of learning, with both training and validation accuracy improving steadily. The final test accuracy of 74.9% is a solid starting point. However, the model's significant weakness lies in its inability to accurately classify minority classes, especially the Dermatofibroma and Melanoma categories. The next step should focus on addressing this class imbalance to build a more robust and clinically useful model.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Summary of What I Learned**\n\nThis project provided a deep and practical understanding of the challenges and solutions involved in modern machine learning model deployment. The key learnings can be summarized as follows:\n\n* Classification of multiple features or variables are harder than binary (malignant or benign).  This definitely needs more time to improve accuracy and work with latest and greatest data.\n  \n* Model Interoperability is Not a Given: While standards like ONNX exist to bridge frameworks, the conversion process is not always a simple one-to-one mapping. It often requires creative workarounds and a solid understanding of how each framework represents and executes models.\n\n* The Power of tf.py_function: I learned that tf.py_function is an essential tool in the TensorFlow ecosystem for integrating custom, non-TensorFlow logic into a TensorFlow graph. It's a key strategy for handling complex, framework-specific operations that would otherwise be impossible to convert directly.\n\n* The Role of Intermediate Formats: ONNX is not just a format; it's a critical bridge in the model lifecycle. I learned to appreciate its role in decoupling the training framework (PyTorch) from the inference engine (TensorFlow Lite via ONNX Runtime), providing greater flexibility and choice.\n\n* The Importance of a Well-Defined Pipeline: The project demonstrated the need for a systematic, multi-step pipeline for model conversion. Each stepâ€”from exporting to an intermediate format to wrapping with custom logic and finally converting for a specific targetâ€”is a distinct phase with its own set of requirements and potential pitfalls.\n\n* Deployment-Oriented Mindset: I learned that model development doesn't end with training. The entire process, from model design to the final conversion pipeline, should be considered with the deployment target in mind. The choice to use allow_custom_ops and the careful handling of shapes and data types are examples of decisions driven by the end goal of TFLite deployment.\n","metadata":{}}]}